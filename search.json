[{"path":"https://ncn-foreigners.github.io/jointCalib/articles/a_theory.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Joint calibration estimators for totals and quantiles","text":"Calibration weighting method commonly used survey sampling adjust original design weights sampled elements reproduce known population totals auxiliary variables (Deville Särndal 1992). Following calibration paradigm, can also used reproduce known population quantiles benchmark variables (Harms Duchesne 2006). technique also used surveys compensate nonsampling errors, nonresponse coverage errors (Särndal Lundström 2005). appropriately adjusting weights, possible ensure consistency known structures key variables data sources, censuses registers, also reduce bias improve precision final estimates. %Calibration weighting also used surveys analysed features asymmetric distributions (presence outliers) compensate negative impact final estimates: calibration weights provide robustness meeting constraints calibration variables weights (Duchesne 1999). article, propose joint calibration approach estimate total quantile order \\(\\alpha\\) variable interest \\(y\\). Final calibration weights \\(w_{k}\\) reproduce known population totals quantiles auxiliary variables. time, help reduce bias improve precision estimates. proposed method based classic approach calibration simultaneously takes account calibration equations totals quantiles auxiliary variables.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/a_theory.html","id":"calibration-estimator-for-a-total","dir":"Articles","previous_headings":"","what":"Calibration estimator for a total","title":"Joint calibration estimators for totals and quantiles","text":"applications goal estimate finite population total \\(\\tau_{y}=\\sum_{k\\U}y_{k}\\) mean \\(\\bar{\\tau}_{y}=\\tau_{y}/N\\) variable interest \\(y\\), \\(U\\) population size \\(N\\). well-known estimator finite population total Horvitz-Thompson estimator, expressed \\(\\hat{\\tau}_{y\\pi}=\\sum_{k=1}^{n}d_{k}y_{k}=\\sum_{k\\s}{d_{k}y_{k}}\\), \\(s\\) denotes probability sample size \\(n\\), \\(d_{k}=1/\\pi_{k}\\) design weight \\(\\pi_{k}\\) first-order inclusion probability \\(\\)-th element population \\(U\\). estimator unbiased \\(\\tau_{Y}\\) .e. \\(E\\left(\\hat{\\tau}_{y\\pi}\\right)=\\tau_{Y}\\). Let \\(\\mathbf{x}_{k}^{\\circ}\\) \\(J_{1}\\)-dimensional vector auxiliary variables (benchmark variables) \\(\\tau_{\\mathbf{x}}=\\sum_{k\\U}\\mathbf{x}_{k}^{\\circ}=\\left(\\sum_{k\\U}x_{k1},\\ldots,\\sum_{k\\U}x_{kJ_{1}}\\right)^T\\) assumed known. cases practice \\(d_{k}\\) weights reproduce known population totals benchmark variables \\(\\mathbf{x}_{k}^{\\circ}\\). means resulting estimate \\(\\hat{\\tau}_{\\mathbf{x}\\pi}=\\sum_{k\\s}{d_{k}\\mathbf{x}_{k}^{\\circ}}\\) equal \\(\\tau_{\\mathbf{x}}\\). main idea calibration look new calibration weights \\(w_{k}\\) close possible original design weights \\(d_{k}\\) reproduce known population totals \\(\\tau_{\\mathbf{x}}\\) exactly. words, order find new calibration weights \\(w_{k}\\) minimise distance function \\(D\\left(\\mathbf{d},\\mathbf{v}\\right)=\\sum _{k\\s}d_{k}\\hspace{2pt} G\\hspace{0pt}\\left(\\frac{v_{k}}{d_{k}}\\right) \\\\textrm{min}\\) fulfil calibration equations \\(\\sum_{k\\s}v_{k}\\mathbf{x}_{k}^{\\circ} = \\sum_{k\\U}\\mathbf{x}_{k}^{\\circ}\\), \\(\\mathbf{d}=\\left(d_{1},\\ldots,d_{n}\\right)^T\\), \\(\\mathbf{v}=\\left(v_{1},\\ldots,v_{n}\\right)^T\\) \\(G\\left(\\cdot\\right)\\) function must satisfy regularity conditions: \\(G\\left(\\cdot\\right)\\) strictly convex twice continuously differentiable, \\(G\\left(\\cdot\\right)\\geq 0\\), \\(G\\left(1\\right)=0\\), \\(G'\\left(1\\right)=0\\) \\(G''\\left(1\\right)=1\\). Examples \\(G\\left(\\cdot\\right)\\) functions given Deville Särndal (1992). instance, \\(G\\left(x\\right)=\\frac{\\left(x-1\\right)^{2}}{2}\\), using method Lagrange multipliers final calibration weights \\(w_{k}\\) can expressed \\(w_{k}=d_{k}+d_{k}\\left(\\tau_{\\mathbf{x}}-\\hat{\\tau}_{\\mathbf{x}\\pi}\\right)^T\\left(\\sum_{j\\s}d_{j}\\mathbf{x}_{j}^{\\circ}\\mathbf{x}_{j}^{\\circ T}\\right)^{-1}\\mathbf{x}_{k}^{\\circ}\\). worth adding order avoid negative large \\(w_{k}\\) weights process minimising \\(D\\left(\\cdot\\right)\\) function, one can consider boundary constraints \\(L\\leq \\frac{w_{k}}{d_{k}}\\leq U\\), \\(\\ 0\\leq L\\leq 1 \\leq U,\\  k=1,\\ldots,n\\). final calibration estimator population total \\(\\tau_{y}\\) can expressed \\(\\hat{\\tau}_{y\\mathbf{x}}=\\sum_{k\\s}w_{k}y_{k}\\), \\(w_{k}\\) calibration weights obtained specific chosen \\(G\\left(\\cdot\\right)\\) function.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/a_theory.html","id":"calibration-estimator-for-a-quantile","dir":"Articles","previous_headings":"","what":"Calibration estimator for a quantile","title":"Joint calibration estimators for totals and quantiles","text":"Harms Duchesne (2006) considered estimation quantiles using calibration approach way similar Deville Särndal (1992) proposed finite population total \\(\\tau_{y}\\). analogy, approach necessary know values auxiliary variables units population. enough know corresponding quantiles benchmark variables. briefly discuss problem finding calibration weights setup. want estimate quantile \\(Q_{y,\\alpha}\\) order \\(\\alpha \\\\left(0,1\\right)\\) variable interest \\(y\\), can expressed \\(Q_{y,\\alpha}=\\mathrm{inf}\\left\\{t\\left|F_{y}\\left(t\\right)\\geq \\alpha \\right.\\right\\}\\), \\(F_{y}\\left(t\\right)=N^{-1}\\sum_{k\\U}H\\left(t-y_{k}\\right)\\) Heavyside function given \\[\\begin{equation}\\label{eq:H} H\\left(t-y_{k}\\right)=\\left\\{ \\begin{array}{ll} 1, & \\ t \\geq y_{k},\\\\ 0, & \\ t<y_{k}.\\\\ \\end{array} \\right. \\end{equation}\\] assume \\(\\mathbf{Q}_{\\mathbf{x},\\alpha}=\\left(Q_{x_{1},\\alpha},\\ldots,Q_{x_{J_{2}},\\alpha}\\right)^{T}\\) vector known population quantiles order \\(\\alpha\\) vector auxiliary variables \\(\\mathbf{x}_{k}^{*}\\), \\(\\alpha \\\\left(0,1\\right)\\) \\(\\mathbf{x}_{k}^{*}\\) \\(J_{2}\\)-dimensional vector auxiliary variables. worth noting , general, numbers \\(J_{1}\\) \\(J_{2}\\) auxiliary variables different. may happen specific auxiliary variable population total corresponding quantile order \\(\\alpha\\) known. However, cases quantiles known continuous auxiliary variables, unlike totals, generally known categorical variables. order find new calibration weights \\(w_{k}\\) reproduce known population quantiles vector \\(Q_{\\mathbf{x},\\alpha}\\), interpolated distribution function estimator \\(F_{y}\\left(t\\right)\\) defined \\(\\hat{F}_{y,cal}(t)=\\frac{\\sum_{k \\s} w_{k} H_{y, s}\\left(t, y_{k}\\right)}{\\sum_{k \\s} w_{k}}\\), Heavyside function formula (\\(\\ref{eq:H}\\)) replaced modified function \\(H_{y, s}\\left(t, y_{k}\\right)\\) given \\[\\begin{equation} H_{y, s}\\left(t, y_{k}\\right)=\\left\\{ \\begin{array}{ll} 1, & y_{k} \\leqslant L_{y, s}(t), \\\\ \\beta_{y, s}\\left(t\\right), & y_{k}=U_{y, s}\\left(t\\right), \\\\ 0, & y_{k}>U_{y, s}\\left(t\\right), \\end{array}\\right. \\end{equation}\\] \\(L_{y, s}\\left(t\\right)=\\max \\left\\{\\left\\{y_{k}, k \\s \\mid y_{k} \\leqslant t\\right\\} \\cup\\{-\\infty\\}\\right\\}\\), \\(U_{y, s}\\left(t\\right)=\\min \\left\\{\\left\\{y_{k}, k \\s \\mid y_{k}>t\\right\\} \\cup\\{\\infty\\}\\right\\}\\) \\(\\beta_{y, s}\\left(t\\right)=\\frac{t-L_{y, s}\\left(t\\right)}{U_{y, s}\\left(t\\right)-L_{y, s}\\left(t\\right)}\\) \\(k=1,\\ldots,n\\), \\(t \\\\mathbb{R}\\). calibration estimator quantile \\(Q_{y,\\alpha}\\) order \\(\\alpha\\) variable \\(y\\) defined \\(\\hat{Q}_{y,cal,\\alpha}=\\hat{F}_{y,cal}^{-1}(\\alpha)\\), vector \\(\\mathbf{w}=\\left(w_{1},\\ldots,w_{n}\\right)^{T}\\) solution optimization problem \\(D\\left(\\mathbf{d},\\mathbf{v}\\right)=\\sum _{k\\s}d_{k}\\hspace{2pt} G\\hspace{0pt}\\left(\\frac{v_{k}}{d_{k}}\\right) \\\\textrm{min}\\) subject calibration constraints \\(\\sum_{k\\s}v_{k}=N\\) \\(\\hat{\\mathbf{Q}}_{\\mathbf{x},cal,\\alpha}=\\left(\\hat{Q}_{x_{1},cal,\\alpha},\\ldots,\\hat{Q}_{x_{J_{2}},cal,\\alpha}\\right)^{T}=\\mathbf{Q}_{\\mathbf{x},\\alpha}\\) equivalently \\(\\hat{F}_{x_{j},cal}\\left(Q_{x_{j},\\alpha}\\right)=\\alpha\\), \\(j=1,\\ldots,J_{2}\\). previous case, \\(G\\left(x\\right)=\\frac{\\left(x-1\\right)^{2}}{2}\\) using method Lagrange multipliers final calibration weights \\(w_{k}\\) can expressed \\(w_{k}=d_{k}+d_{k}\\left(\\mathbf{T_{}}-\\sum_{k\\s}{d_{k}\\mathbf{}_{k}}\\right)^{T}\\left(\\sum_{j\\s}{d_{j}}\\mathbf{}_{j}\\mathbf{}_{j}^{T}\\right)^{-1}\\mathbf{}_{k}\\), \\(\\mathbf{T_{}}=\\left(N,\\alpha,\\ldots,\\alpha\\right)^{T}\\) elements \\(\\mathbf{}_{k}=\\left(1,a_{k1},\\ldots,a_{kJ_{2}}\\right)^{T}\\) given \\[\\begin{equation} a_{kj}=\\left\\{\\begin{array}{lll} N^{-1},& \\quad x_{kj}\\leq L_{x_{j},s}\\left(Q_{x_{j},\\alpha}\\right),\\\\ N^{-1}\\beta_{x_{j},s}\\left(Q_{x_{j},\\alpha}\\right), & \\quad x_{kj}=U_{x_{j},s}\\left(Q_{x_{j},\\alpha}\\right),\\\\ 0,& \\quad x_{kj}> U_{x_{j},s}\\left(Q_{x_{j},\\alpha}\\right),\\\\ \\end{array} \\right. \\end{equation}\\] \\(j=1,\\ldots,J_{2}\\). Assuming \\(y_{1}\\leq y_{2}\\ldots \\leq y_{n}\\) can shown exists \\(p\\!\\\\!\\!{\\left\\{1,\\ldots,n-1\\right\\}}\\) \\(\\hat{F}_{y,cal}\\left(y_{p}\\right)\\leq \\alpha\\), \\(\\hat{F}_{y,cal}\\left(y_{p+1}\\right)> \\alpha\\) \\(\\hat{F}_{y,cal}\\) invertible point \\(\\hat{Q}_{y,cal,\\alpha}\\) calibration estimator \\(\\hat{Q}_{y,cal,\\alpha}\\) quantile \\(Q_{y,\\alpha}\\) order \\(\\alpha \\\\left(0,1\\right)\\) can expressed \\(\\hat{Q}_{y,cal,\\alpha}=y_{p}+\\frac{N\\alpha-\\sum_{=1}^{p}{w_{}}}{w_{p+1}}\\left(y_{p+1}-y_{p}\\right)\\).","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/a_theory.html","id":"joint-calibration-of-totals-and-quantiles","dir":"Articles","previous_headings":"","what":"Joint calibration of totals and quantiles","title":"Joint calibration estimators for totals and quantiles","text":"propose simple method jointly calibrates weights totals quantiles. resulting calibrated weights \\(w_{k}\\) allow us retrieve known population totals quantiles auxiliary variables simultaneously. case single scalar auxiliary variable \\(x\\), final calibration estimator based weights \\(w_{k}\\) delivers exact population total quantile variable \\(y\\) relationship \\(y\\) \\(x\\) exactly linear .e. \\(y_{k}=\\beta x_{k}\\) \\(k\\U\\). Let us assume interested estimating population total \\(\\tau_{y}\\) /quantile \\(Q_{y,\\alpha}\\) order \\(\\alpha\\), \\(\\alpha \\\\left(0,1\\right)\\) variable interest \\(y\\). Let \\(\\mathbf{x}_{k}=\\left(\\begin{smallmatrix}\\mathbf{x}_{k}^{\\circ}\\\\1\\\\\\mathbf{x}_{k}^{*}\\end{smallmatrix}\\right)\\) \\(J+1\\)-dimensional vector auxiliary variables, \\(J=J_{1}+J_{2}\\). assume \\(J_{1}\\) variables vector population totals \\(\\tau_{\\mathbf{x}}\\) known \\(J_{2}\\) variables vector \\(\\mathbf{Q}_{\\mathbf{x},\\alpha}\\) population quantiles known. practice may happen auxiliary variable know population total quantile. require complete auxiliary information described vector \\(\\mathbf{x}_{k}\\) known \\(k\\U\\); however, auxiliary variables unit-population data necessary, accurate quantiles likely known sources (Särndal 2007). main aim find new calibration weights \\(w_{k}\\) close possible original design weights \\(d_{k}\\) auxiliary variables reproduce known population totals remaining benchmark variables – reproduce known population quantiles exactly. joint approach looking vector \\(\\mathbf{w}=\\left(w_{1},\\ldots,w_{n}\\right)^{T}\\) solution optimization problem \\(D\\left(\\mathbf{d},\\mathbf{v}\\right)=\\sum _{k\\s}d_{k}\\hspace{2pt} G\\hspace{0pt}\\left(\\frac{v_{k}}{d_{k}}\\right) \\\\textrm{min}\\) subject calibration constraints \\(\\sum_{k\\s}v_{k}=N\\), \\(\\sum_{k\\s}v_{k}\\mathbf{x}_{k}^{\\circ} = \\tau_{\\mathbf{x}}\\) \\(\\hat{\\mathbf{Q}}_{\\mathbf{x},cal,\\alpha}=\\mathbf{Q}_{\\mathbf{x},\\alpha}\\). general, \\(J+1\\) calibration equations fulfilled. Alternatively, calibration equations can expressed \\(\\sum_{k\\s}v_{k}\\mathbf{x}_{k}^{\\circ} = \\tau_{\\mathbf{x}}\\) \\(\\sum_{k\\s}v_{k}\\mathbf{}_{k}=\\mathbf{T_{}}\\) possible boundary constraints calibration weights. Assuming quadratic metric \\(D\\left(\\cdot\\right)\\), based \\(G\\left(x\\right)=\\frac{\\left(x-1\\right)^{2}}{2}\\) function, explicit solution optimization problem can derived. solution similar calibration weights totals quantiles. Let \\(\\mathbf{h}_{\\mathbf{x}}=\\binom{\\tau_{\\mathbf{x}}}{\\mathbf{T_{}}}\\) \\(\\hat{\\mathbf{h}}_{\\mathbf{x}}=\\binom{\\sum_{k\\s}d_{k}\\mathbf{x}_{k}^{\\circ}}{\\sum_{k\\s}d_{k}\\mathbf{}_{k}}\\). vector calibration weights \\(\\mathbf{w}=\\left(w_{1},\\ldots,w_{n}\\right)^{T}\\) solves optimization problem satisfies relation: \\[\\begin{equation} w_{k}=d_{k}+d_{k}\\left(\\mathbf{h}_{\\mathbf{x}}-\\hat{\\mathbf{h}}_{\\mathbf{x}}\\right)^{T}\\left(\\sum_{j\\s}{d_{j}}\\mathbf{x}_{j}\\mathbf{x}_{j}^{T}\\right)^{-1}\\mathbf{x}_{k}. \\end{equation}\\] Remark 1: proposed method assume reproduce known population totals known population quantiles set benchmark variables simultaneously. approach can easily extended assuming estimated totals quantiles reproduced auxiliary variables. Moreover, assumed process calibration based particular quantile (order \\(\\alpha\\)). instance, median .e. \\(\\alpha=0.5\\). Nothing stands way searching calibration weights reproduce population totals set population quantiles (example quartiles) chosen set auxiliary variables. Moreover, proposed method can easily extended generalized calibration, particular, missing random non-response (Kott Chang 2010), empirical likelihood adding additional constraints quantiles, .e. \\(\\sum_{k \\s} p_{k}a_{kj} = \\frac{\\alpha}{N}\\), \\(j=1,\\ldots,J_{2}\\) \\(p_{k}\\) elements vector \\(\\mathbf{p}=\\left(p_{1},\\ldots,p_{n}\\right)^{T}\\) discrete probability measure sample \\(s\\) (Wu Thompson 2020). Remark 2: approach use interpolated distribution function \\(H_{y,s}\\), simple modification Heavyside function defined (\\(\\ref{H}\\)). practical point view smooth approximation step function, based logistic function can used .e. \\(H\\left(x\\right)\\approx\\frac{1}{2}+\\frac{1}{2}\\tanh{kx}=\\frac{1}{1+e^{-2kx}}\\), larger value \\(k\\) corresponds sharper transition \\(x = 0\\). Remark 3: proposed method can easily applied data household surveys, integrated calibration applied, .e. weights particular household members equal. can particularly useful case EU-SILC, information administrative data can used provide population distributions auxiliary variables.","code":""},{"path":[]},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/b_survey.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Calibration of quantiles and a joint calibration of totals and quanitles for surveys","text":"","code":"library(jointCalib) library(survey) #> Loading required package: grid #> Loading required package: Matrix #> Loading required package: survival #>  #> Attaching package: 'survey' #> The following object is masked from 'package:graphics': #>  #>     dotchart library(laeken) library(ebal) #> ## #> ## ebal Package: Implements Entropy Balancing. #> ## See http://www.stanford.edu/~jhain/ for additional information."},{"path":[]},{"path":[]},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/b_survey.html","id":"setup-1","dir":"Articles","previous_headings":"Examples > Basic example","what":"Setup","title":"Calibration of quantiles and a joint calibration of totals and quanitles for surveys","text":"Generate small dataset Calibrate using: + totals: x1 x2, + median : x2. Median x2 calibration.","code":"set.seed(123) N <- 100 x1 <- rbinom(n = 100, prob = 0.7, size = 1) x2 <- rlnorm(n = 100)*1000 pop<-data.frame(x1, x2) sample_df <- pop[sample(1:N, 20), ] sample_df$d <- as.integer(N/nrow(sample_df)) colSums(sample_df[, c(\"x1\", \"x2\")]*sample_df$d) #>       x1       x2  #>     70.0 181454.5 with(sample_df, weightedMedian(x2, d)) #> [1] 1005.781 res <- joint_calib(formula_totals = ~ x1 + x2,                    formula_quantiles = ~ x2,                    data = sample_df,                    dweights = as.numeric(sample_df$d),                    N = 100,                    pop_totals = c(x1=sum(x1), x2=sum(x2)),                    pop_quantiles = list(x2=quantile(x2,0.5)),                    method = \"linear\",                    control = control_calib(interpolation = \"linear\"))  for_example <- res$Xs[, c(3,4,2)] |> as.data.frame() for_example$w <- sample_df$d * res$g for_example #>    x1        x2           V3        w #> 90  1  236.0072 0.0100000000 5.550384 #> 58  0  188.6349 0.0100000000 5.805215 #> 81  1 4239.9474 0.0000000000 3.892356 #> 29  1 1198.7789 0.0000000000 5.319617 #> 26  0 2788.6884 0.0000000000 4.806049 #> 27  1  752.1850 0.0100000000 5.308135 #> 85  1  128.3176 0.0100000000 5.600924 #> 7   1  212.5129 0.0100000000 5.561410 #> 60  1 2506.7739 0.0000000000 4.705757 #> 96  1  588.0716 0.0100000000 5.385155 #> 41  1 2700.6807 0.0000000000 4.614754 #> 84  0  655.4083 0.0100000000 5.586152 #> 6   1 4556.1164 0.0000000000 3.743974 #> 31  0 1005.7808 0.0008372057 5.624283 #> 17  1 1565.5071 0.0000000000 5.147506 #> 64  1  945.9534 0.0000000000 5.438271 #> 37  0 2994.6849 0.0000000000 4.709372 #> 57  1  456.1633 0.0100000000 5.447062 #> 20  0 7768.5590 0.0000000000 2.468930 #> 35  1  802.1284 0.0100000000 5.284696 weightedQuantile(sample_df$x2, res$g, 0.5) #> [1] 945.9534"},{"path":[]},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/b_survey.html","id":"setup-2","dir":"Articles","previous_headings":"Examples > Example 1 – census case","what":"Setup","title":"Calibration of quantiles and a joint calibration of totals and quanitles for surveys","text":"Based Haziza, D., Lesage, É. (2016). discussion weighting procedures unit nonresponse. Journal Official Statistics, 32(1), 129-145.","code":"set.seed(20230817) N <- 1000 x <- runif(N, 0, 80) #y <- 1000+10*x+rnorm(N, 0, 300) #y <- exp(-0.1 + 0.1*x) + rnorm(N, 0, 300) #y <- rbinom(N, 1, prob = 1/(exp(-0.5*(x-55))+1)) y <- 1300-(x-40)^2 + rnorm(N, 0, 300) #p <- rbinom(N, 1, prob = 0.2+0.6*(1 + exp(-5 + x/8))^-1) p <- rbinom(N, 1, prob = 0.07+0.45*(x/40-1)^2+0.0025*x) #p <- rbinom(N, 1, prob = (1.2+0.024*x)^-1) #p <- rbinom(N, 1, prob = exp(-0.2 - 0.014*x)) probs <- seq(0.1, 0.9, 0.1) quants_known <- list(x=quantile(x, probs)) totals_known <- c(x=sum(x)) df <- data.frame(x, y, p) df_resp <- df[df$p == 1, ] df_resp$d <- N/nrow(df_resp) y_quant_true <- quantile(y, probs) head(df_resp) #>           x        y p        d #> 6  12.35687 444.9053 1 3.134796 #> 7  61.90319 403.9473 1 3.134796 #> 13 60.96079 923.4975 1 3.134796 #> 14 76.85300 124.4110 1 3.134796 #> 18 71.52828 422.0934 1 3.134796 #> 19 65.32808 740.4801 1 3.134796"},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/b_survey.html","id":"using-jointcalib-package","dir":"Articles","previous_headings":"Examples > Example 1 – census case","what":"Using jointCalib package","title":"Calibration of quantiles and a joint calibration of totals and quanitles for surveys","text":"example 1a: calibrate quantiles (deciles) example 1b: calibrate quantiles (deciles) can restrict weights specific range using logit. Empirical likelihood method can applied using following code Entropy balancing method can applied using following code Finally, compare method true Y distribution est_y1 – weights calibrated quantiles , est_y2 – weights calibrated quantiles totals, est_y3 – weights calibrated quantiles totals using logit distance range limitations, est_y4 – weights calibrated means using el. est_y5 – weights calibrated quantiles using el. est_y6 – weights calibrated quantiles totals using el. est_y7 – weights calibrated quantiles totals using eb. sum squares calibration totals means seems best.","code":"result1 <- joint_calib(formula_quantiles = ~x,                       data=df_resp,                       dweights=df_resp$d,                       N = N,                       pop_quantiles = quants_known,                       method = \"linear\",                       backend = \"sampling\") result1 #> Weights calibrated using: linear with sampling backend. #> Summary statistics for g-weights: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.4562  0.6773  0.8180  1.0000  1.4500  2.4538  #> Totals and precision (abs diff: 4.574665e-10) #>        totals    precision #> N       1e+03 4.557705e-10 #> x 0.10  1e-01 5.020984e-14 #> x 0.20  2e-01 1.055545e-13 #> x 0.30  3e-01 1.324496e-13 #> x 0.40  4e-01 1.580958e-13 #> x 0.50  5e-01 1.765255e-13 #> x 0.60  6e-01 1.991740e-13 #> x 0.70  7e-01 2.304823e-13 #> x 0.80  8e-01 2.882139e-13 #> x 0.90  9e-01 3.552714e-13 data.frame(true = quants_known$x, est = weightedQuantile(df_resp$x, result1$g*df_resp$d, probs)) #>          true       est #> 10%  7.078067  7.085003 #> 20% 14.831221 14.824424 #> 30% 23.146180 23.287657 #> 40% 31.641911 31.802986 #> 50% 39.033812 39.154276 #> 60% 47.527168 48.252065 #> 70% 54.984229 55.311953 #> 80% 64.073167 64.062629 #> 90% 71.565441 71.567274 result2 <- joint_calib(formula_totals = ~x,                        formula_quantiles = ~x,                        data = df_resp,                        dweights = df_resp$d,                        N = N,                        pop_quantiles = quants_known,                        pop_totals = totals_known,                        method = \"linear\",                        backend = \"sampling\") summary(result2$g) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.3563  0.6208  0.8199  1.0000  1.4368  2.5384 data.frame(true = quants_known$x, est = weightedQuantile(df_resp$x, result2$g*df_resp$d, probs)) #>          true       est #> 10%  7.078067  7.085003 #> 20% 14.831221 14.824424 #> 30% 23.146180 23.287657 #> 40% 31.641911 31.802986 #> 50% 39.033812 39.154276 #> 60% 47.527168 48.252065 #> 70% 54.984229 55.311953 #> 80% 64.073167 64.062629 #> 90% 71.565441 71.567274 result3 <- joint_calib(formula_totals = ~x,                        formula_quantiles = ~x,                        data = df_resp,                        dweights = df_resp$d,                        N = N,                        pop_quantiles = quants_known,                        pop_totals = totals_known,                        method = \"logit\",                        backend = \"sampling\",                         maxit = 500,                        bounds = c(0, 3))  summary(result3$g) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.3911  0.6254  0.8140  1.0000  1.4325  2.5186 data.frame(true = quants_known$x, est = weightedQuantile(df_resp$x, result3$g*df_resp$d, probs)) #>          true       est #> 10%  7.078067  7.085003 #> 20% 14.831221 14.824424 #> 30% 23.146180 22.872078 #> 40% 31.641911 31.297922 #> 50% 39.033812 39.154276 #> 60% 47.527168 48.252065 #> 70% 54.984229 55.311953 #> 80% 64.073167 64.529683 #> 90% 71.565441 71.567274 result4a <- joint_calib(formula_quantiles = ~ x,                         data = df_resp,                         dweights = df_resp$d,                         N = N,                         pop_quantiles = quants_known,                         method = \"el\",                         backend = \"base\") summary(result4a$g) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.4563  0.6773  0.8180  1.0000  1.4500  2.4538  result4b <- joint_calib(formula_totals = ~ x,                         formula_quantiles = ~ x,                         data = df_resp,                         dweights = df_resp$d,                         N = N,                         pop_quantiles = quants_known,                         pop_totals = totals_known,                         method = \"el\",                         backend = \"base\")  summary(result4b$g) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.4414  0.6584  0.8109  1.0000  1.4256  2.8513  result4c <- calib_el(X = result4b$Xs[, c(1, 11)],                      d = df_resp$d,                       totals = c(N,totals_known),                      maxit = 50,                      tol = 1e-8)  summary(result4c) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.7438  0.7910  0.8848  1.0000  1.2455  1.4923 data.frame(true = quants_known$x,             est = weightedQuantile(df_resp$x, result2$g*df_resp$d, probs),            est_el0 = weightedQuantile(df_resp$x, result4c*df_resp$d, probs),            est_el1 = weightedQuantile(df_resp$x, result4a$g*df_resp$d, probs),            est_el2 = weightedQuantile(df_resp$x, result4b$g*df_resp$d, probs)) #>          true       est   est_el0   est_el1   est_el2 #> 10%  7.078067  7.085003  3.640246  7.085003  7.085003 #> 20% 14.831221 14.824424  8.024948 14.824424 14.824424 #> 30% 23.146180 23.287657 14.499018 23.287657 23.287657 #> 40% 31.641911 31.802986 24.010501 31.802986 31.802986 #> 50% 39.033812 39.154276 39.154276 38.892342 39.154276 #> 60% 47.527168 48.252065 54.685438 48.252065 48.252065 #> 70% 54.984229 55.311953 63.084405 54.954054 54.954054 #> 80% 64.073167 64.062629 70.050593 64.062629 64.062629 #> 90% 71.565441 71.567274 75.663078 71.567274 71.567274 result5 <- joint_calib(formula_quantiles = ~ x,                         data = df_resp,                         dweights = df_resp$d,                         N = N,                         pop_quantiles = quants_known,                         method = \"eb\") summary(result5$g) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.4576  0.6775  0.8180  1.0003  1.4500  2.4538 results_y <- data.frame(true_y = y_quant_true,                         est_y1 = weightedQuantile(df_resp$y, result1$g * df_resp$d, probs),                         est_y2 = weightedQuantile(df_resp$y, result2$g * df_resp$d, probs),                         est_y3 = weightedQuantile(df_resp$y, result3$g * df_resp$d, probs),                         est_y4 = weightedQuantile(df_resp$y, result4c * df_resp$d, probs),                         est_y5 = weightedQuantile(df_resp$y, result4a$g * df_resp$d, probs),                         est_y6 = weightedQuantile(df_resp$y, result4b$g * df_resp$d, probs),                         est_y7 = weightedQuantile(df_resp$y, result5$g * df_resp$d, probs))  results_y #>         true_y     est_y1     est_y2     est_y3     est_y4     est_y5 #> 10%  -56.97982  -36.18473  -36.18473  -36.18473 -149.00996  -36.18473 #> 20%  210.58301  228.75429  228.75429  228.75429   17.27107  228.75429 #> 30%  444.81652  413.22517  417.60155  413.22517  203.58302  413.22517 #> 40%  646.06099  622.82192  622.82192  622.82192  381.99560  622.82192 #> 50%  803.50842  789.89936  789.89936  789.89936  503.35849  789.89936 #> 60%  975.31803  925.84730  925.84730  925.84730  679.04530  925.84730 #> 70% 1123.44643 1023.75230 1023.75230 1023.75230  811.84389 1023.75230 #> 80% 1245.62645 1162.06504 1162.06504 1162.06504 1009.46703 1162.06504 #> 90% 1449.23819 1471.33301 1471.33301 1471.33301 1242.60357 1471.33301 #>         est_y6     est_y7 #> 10%  -36.18473  -36.18473 #> 20%  228.75429  228.75429 #> 30%  411.47088  413.22517 #> 40%  622.82192  622.82192 #> 50%  789.89936  789.89936 #> 60%  925.84730  925.84730 #> 70% 1023.75230 1023.75230 #> 80% 1162.06504 1162.06504 #> 90% 1471.33301 1471.33301 apply(results_y[, -1], 2, FUN = function(x) sum((x-results_y[,1])^2)) #>    est_y1    est_y2    est_y3    est_y4    est_y5    est_y6    est_y7  #>  22342.87  22085.51  22342.87 547195.99  22342.87  22456.79  22342.87"},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/b_survey.html","id":"using-survey-package","dir":"Articles","previous_headings":"Examples > Example 1 – census case","what":"Using survey package","title":"Calibration of quantiles and a joint calibration of totals and quanitles for surveys","text":"example 1a: calibrate quantiles (deciles) Calibration using calibrate Calibration using grake (low level)","code":"A <- joint_calib_create_matrix(X_q = model.matrix(~x+0, df_resp), N = N, pop_quantiles = quants_known) colnames(A) <- paste0(\"quant_\", gsub(\"\\\\D\", \"\", names(quants_known$x))) A <- as.data.frame(A) df_resp <- cbind(df_resp, A) head(df_resp) #>           x        y p        d quant_10 quant_20 quant_30 quant_40 quant_50 #> 6  12.35687 444.9053 1 3.134796        0    0.001    0.001    0.001    0.001 #> 7  61.90319 403.9473 1 3.134796        0    0.000    0.000    0.000    0.000 #> 13 60.96079 923.4975 1 3.134796        0    0.000    0.000    0.000    0.000 #> 14 76.85300 124.4110 1 3.134796        0    0.000    0.000    0.000    0.000 #> 18 71.52828 422.0934 1 3.134796        0    0.000    0.000    0.000    0.000 #> 19 65.32808 740.4801 1 3.134796        0    0.000    0.000    0.000    0.000 #>    quant_60 quant_70 quant_80 quant_90 #> 6     0.001    0.001    0.001    0.001 #> 7     0.000    0.000    0.001    0.001 #> 13    0.000    0.000    0.001    0.001 #> 14    0.000    0.000    0.000    0.000 #> 18    0.000    0.000    0.000    0.001 #> 19    0.000    0.000    0.000    0.001 m1 <- svydesign(ids = ~1, data = df_resp, weights = ~d) quants_formula <- as.formula(paste(\"~\", paste(colnames(A), collapse = \"+\"))) quants_formula #> ~quant_10 + quant_20 + quant_30 + quant_40 + quant_50 + quant_60 +  #>     quant_70 + quant_80 + quant_90 svytotal(quants_formula, m1) #>            total     SE #> quant_10 0.10972 0.0175 #> quant_20 0.23197 0.0237 #> quant_30 0.29154 0.0255 #> quant_40 0.34796 0.0267 #> quant_50 0.38871 0.0273 #> quant_60 0.43887 0.0278 #> quant_70 0.50784 0.0280 #> quant_80 0.63323 0.0270 #> quant_90 0.78100 0.0232 pop_totals <- c(N, probs) names(pop_totals) <- c(\"(Intercept)\", colnames(A)) m1_cal <- calibrate(m1, quants_formula, pop_totals) svytotal(quants_formula, m1_cal) #>          total SE #> quant_10   0.1  0 #> quant_20   0.2  0 #> quant_30   0.3  0 #> quant_40   0.4  0 #> quant_50   0.5  0 #> quant_60   0.6  0 #> quant_70   0.7  0 #> quant_80   0.8  0 #> quant_90   0.9  0 g1 <- grake(mm = as.matrix(cbind(1, A)),             ww = df_resp$d,             calfun = cal.linear,             population = pop_totals,             bounds = list(lower = -Inf, upper = Inf),             epsilon = 1e-7,             verbose = FALSE,             maxit = 50,             variance = NULL) summary(as.numeric(g1)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.4562  0.6773  0.8180  1.0000  1.4500  2.4538"},{"path":[]},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/d_causal.html","id":"distributional-entropy-balancing","dir":"Articles","previous_headings":"Theory","what":"Distributional entropy balancing","title":"Balancing distributions for observational studies","text":"proposal, leads distributional entropy balancing (hereinafter DEB), based extending original idea adding additional constraint(s) weights \\(\\mathbf{}_k\\), presented . \\[ \\begin{aligned} \\max _{w} H(w)=- & \\sum_{k \\s_0} v_{k} \\log \\left(v_{k} / q_{k}\\right), \\\\ \\text { s.t. } & \\sum_{k \\s_0} v_{k} G_{k j}=m_{k} \\text { } j \\1, \\ldots, J_1, \\\\ & \\sum_{k \\s_0} v_{k} a_{k j}=\\frac{\\alpha_{j}}{n_1} \\text { } j \\1, \\ldots, J_2, \\\\ & \\sum_{k \\s_0} v_{k}=1 \\text { } v \\geq 0 \\text { } k \\s_0. \\end{aligned} \\]","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/d_causal.html","id":"distributional-propensity-score-method","dir":"Articles","previous_headings":"Theory","what":"Distributional propensity score method","title":"Balancing distributions for observational studies","text":"(imai2014covariate?) proposed covariate balancing propensity score (CBPS) estimate (eqref?){eq-ate}, unknown parameters propensity score model \\(\\mathbf{\\gamma}\\) estimated using generalized method moments \\[ \\mathbb{E}\\left[\\left(\\frac{\\mathcal{D}}{p\\left(\\mathbf{X}; \\mathbf{\\gamma}\\right)}-\\frac{1-\\mathcal{D}}{1-p\\left(\\mathbf{X}; \\mathbf{\\gamma}\\right)}\\right) f(\\mathbf{X})\\right]=\\mathbf{0}, \\label{eq-cbps} \\] \\(p()\\) propensity score. balances means \\(\\mathbf{X}\\) variables, may sufficient variables highly skewed interested estimating DTE QTE. propose simple approach based specification moments \\(\\alpha\\)-quantiles balanced. Instead using matrix \\(\\mathbf{X}\\), propose use matrix \\(\\mathcal{X}\\), constructed follows \\[ \\mathcal{X} = \\begin{bmatrix} \\mathbf{1}^1 & \\mathbf{X}^1 & \\mathbf{}^1\\\\ \\mathbf{1}^0 & \\mathbf{X}^0 & \\mathbf{}^0\\\\ \\end{bmatrix}, \\] \\(\\mathbf{X}^0, \\mathbf{X}^1\\) matrices size \\(n_0 \\times J_1\\) \\(n_1 \\times J_1\\) \\(J_1\\) covariates balanced means, \\(\\mathbf{}^1, \\mathbf{}^0\\) matrices based \\(J_2\\) covariates elements defined follows \\[ ^1_{kj}=\\left\\{\\begin{array}{lll} n_1^{-1},& \\quad x_{kj}^1\\leq L_{x_{j},1}\\left(q^1_{x_{j},\\alpha}\\right),\\\\ n_1^{-1}\\beta_{x_{j},1}\\left(q^1_{x_{j},\\alpha}\\right), & \\quad x_{kj}^1=U_{x_{j},1}\\left(q^1_{x_{j},\\alpha}\\right),\\\\ 0,& \\quad x^1_{kj}> U_{x_{j},1}\\left(q^1_{x_{j},\\alpha}\\right),\\\\ \\end{array} \\right. \\] \\[ ^0_{kj}=\\left\\{\\begin{array}{lll} n_1^{-1},& \\quad x_{kj}^0\\leq L_{x_{j},0}\\left(q^1_{x_{j},\\alpha}\\right),\\\\ n_1^{-1}\\beta_{x_{j},0}\\left(q^1_{x_{j},\\alpha}\\right), & \\quad x_{kj}^0=U_{x_{j},0}\\left(q^1_{x_{j},\\alpha}\\right),\\\\ 0,& \\quad x^0_{kj}> U_{x_{j},0}\\left(q^1_{x_{j},\\alpha}\\right),\\\\ \\end{array} \\right. \\] \\(n_1\\) size treatment group, alternatively logistic function \\(\\eqref{eq-logistic-}\\) can used.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/d_causal.html","id":"packages","dir":"Articles","previous_headings":"","what":"Packages","title":"Balancing distributions for observational studies","text":"Load packages example Read LaLonde data CBPS package.","code":"library(jointCalib) library(CBPS) #> Loading required package: MASS #> Loading required package: MatchIt #> Loading required package: nnet #> Loading required package: numDeriv #> Loading required package: glmnet #> Loading required package: Matrix #> Loaded glmnet 4.1-8 #> CBPS: Covariate Balancing Propensity Score #> Version: 0.23 #> Authors: Christian Fong [aut, cre], #>   Marc Ratkovic [aut], #>   Kosuke Imai [aut], #>   Chad Hazlett [ctb], #>   Xiaolin Yang [ctb], #>   Sida Peng [ctb], #>   Inbeom Lee [ctb] library(ebal) #> ## #> ## ebal Package: Implements Entropy Balancing. #> ## See http://www.stanford.edu/~jhain/ for additional information. library(laeken) data(\"LaLonde\", package = \"CBPS\") head(LaLonde) #>     exper treat age educ black hisp married nodegr re74 re75 re78 re74.miss #> 298     0     0  47   12     0    0       0      0    0    0    0         0 #> 299     0     0  50   12     1    0       1      0    0    0    0         1 #> 300     0     0  44   12     0    0       0      0    0    0    0         0 #> 301     0     0  28   12     1    0       1      0    0    0    0         1 #> 302     0     0  54   12     0    0       1      0    0    0    0         1 #> 303     0     0  55   12     0    1       1      0    0    0    0         1"},{"path":[]},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/d_causal.html","id":"single-variable-age","dir":"Articles","previous_headings":"ATT with entropy balancing and other methods","what":"Single variable: age","title":"Balancing distributions for observational studies","text":"First, start age variable. can find distribution age control treatment group.  Basic descriptive statistics given . Nowe, let’s use ebal::ebalance jointCalib::joint_calib_att method eb (uses uses ebal package backend). DEB use deciles probs = seq(0.1, 0.9, 0.1) balance mean well (formula_means = ~ age). output informs target (totals) quantiles difference balanced target quantities (column precision). Compare weighted distributions treatment group distribution.  Compare balancing weights.","code":"dens0 <- density(LaLonde$age[LaLonde$treat == 0]) dens1 <- density(LaLonde$age[LaLonde$treat == 1]) plot(dens0, main=\"Distribution of age\", xlab=\"Age\", ylim=c(0, max(dens0$y, dens1$y)), col = \"blue\") lines(dens1, lty=2, col=\"red\") legend(\"topright\", legend=c(\"Control\", \"Treatment\"), lty=c(1,2), col=c(\"blue\", \"red\")) aggregate(age ~ treat, data = LaLonde, FUN = quantile) #>   treat age.0% age.25% age.50% age.75% age.100% #> 1     0   17.0    25.0    31.0    42.5     55.0 #> 2     1   17.0    20.0    23.0    27.0     49.0 bal_standard <- ebalance(LaLonde$treat, X = LaLonde[, \"age\"]) #> Converged within tolerance bal_quant <- joint_calib_att(formula_means = ~ age,                               formula_quantiles = ~ age,                               treatment =  ~ treat,                               data = LaLonde,                               probs = seq(0.1, 0.9, 0.1),                              method = \"eb\") bal_quant #> Weights calibrated using: eb with ebal backend. #> Summary statistics for g-weights: #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.007665 0.022555 0.046914 0.101888 0.194177 0.605874  #> Totals and precision (abs diff: 0.1299956) #>          totals    precision #> N         297.0 2.632778e-03 #> age 0.10    0.1 1.688971e-10 #> age 0.20    0.2 3.377950e-10 #> age 0.30    0.3 5.067252e-10 #> age 0.40    0.4 3.901260e-09 #> age 0.50    0.5 6.496023e-09 #> age 0.60    0.6 1.144491e-08 #> age 0.70    0.7 3.277056e-08 #> age 0.80    0.8 5.172449e-08 #> age 0.90    0.9 1.811425e-07 #> age      7314.0 1.273625e-01 dens0 <- density(LaLonde$age[LaLonde$treat == 0], weights = bal_standard$w/sum(bal_standard$w)) #> Warning in density.default(LaLonde$age[LaLonde$treat == 0], weights = #> bal_standard$w/sum(bal_standard$w)): Selecting bandwidth *not* using 'weights' dens1 <- density(LaLonde$age[LaLonde$treat == 0], weights = bal_quant$g/sum(bal_quant$g)) #> Warning in density.default(LaLonde$age[LaLonde$treat == 0], weights = #> bal_quant$g/sum(bal_quant$g)): Selecting bandwidth *not* using 'weights' dens2 <- density(LaLonde$age[LaLonde$treat == 1]) plot(dens0, main=\"Distribution of age\", xlab=\"Age\", ylim=c(0, max(dens0$y, dens1$y))) lines(dens1, lty=2, col=\"blue\") lines(dens2, lty=3, col=\"red\") legend(\"topright\",         legend=c(\"EB\", \"DEB\", \"Treatment\"),         lty=c(1,2, 3),         col=c(\"black\", \"blue\", \"red\")) plot(x = bal_standard$w,      y = bal_quant$g,       xlab = \"EB\", ylab = \"DEB\", main = \"Comparison of EB and DEB weights\",      xlim = c(0, 0.7), ylim = c(0, 0.7))"},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/d_causal.html","id":"more-variables","dir":"Articles","previous_headings":"ATT with entropy balancing and other methods","what":"More variables","title":"Balancing distributions for observational studies","text":"Now, consider three variables: married, age educ.  code balances control treatment group age educ means quantiles. Compare distribution education (educ) variable.  Compare distribution age (age) variable.  Compare balancing weights.","code":"dens0 <- density(LaLonde$educ[LaLonde$treat == 0]) dens1 <- density(LaLonde$educ[LaLonde$treat == 1]) plot(dens0, main=\"Distribution of education\", xlab=\"Education\", ylim=c(0, max(dens0$y, dens1$y)), col = \"blue\") lines(dens1, lty=2, col=\"red\") legend(\"topleft\", legend=c(\"Control\", \"Treatment\"), lty=c(1,2), col=c(\"blue\", \"red\")) bal_standard <- ebalance(LaLonde$treat, X = LaLonde[, c(\"married\", \"age\", \"educ\")]) #> Converged within tolerance bal_quant <- joint_calib_att(formula_means = ~ married + age + educ,                               formula_quantiles = ~ age + educ,                               treatment =  ~ treat,                               data = LaLonde,                               method = \"eb\") bal_quant #> Weights calibrated using: eb with ebal backend. #> Summary statistics for g-weights: #>      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.  #> 0.0003863 0.0075341 0.0258057 0.1018874 0.0606804 2.8081281  #> Totals and precision (abs diff: 0.08993871) #>            totals    precision #> N          297.00 1.646454e-03 #> age 0.25     0.25 6.697796e-08 #> age 0.50     0.50 1.541813e-07 #> age 0.75     0.75 4.802355e-07 #> educ 0.25    0.25 2.806495e-06 #> educ 0.50    0.50 3.414877e-06 #> educ 0.75    0.75 4.188730e-06 #> married     50.00 8.466613e-04 #> age       7314.00 7.261357e-02 #> educ      3083.00 1.482091e-02 dens0 <- density(LaLonde$educ[LaLonde$treat == 0], weights = bal_standard$w/sum(bal_standard$w)) #> Warning in density.default(LaLonde$educ[LaLonde$treat == 0], weights = #> bal_standard$w/sum(bal_standard$w)): Selecting bandwidth *not* using 'weights' dens1 <- density(LaLonde$educ[LaLonde$treat == 0], weights = bal_quant$g/sum(bal_quant$g)) #> Warning in density.default(LaLonde$educ[LaLonde$treat == 0], weights = #> bal_quant$g/sum(bal_quant$g)): Selecting bandwidth *not* using 'weights' dens2 <- density(LaLonde$educ[LaLonde$treat == 1]) plot(dens0, main=\"Distribution of Education\", xlab=\"Education\", ylim=c(0, max(dens0$y, dens1$y))) lines(dens1, lty=2, col=\"blue\") lines(dens2, lty=3, col=\"red\") legend(\"topleft\",         legend=c(\"EB\", \"DEB\", \"Treatment\"),         lty=c(1,2, 3),         col=c(\"black\", \"blue\", \"red\")) dens0 <- density(LaLonde$age[LaLonde$treat == 0], weights = bal_standard$w/sum(bal_standard$w)) #> Warning in density.default(LaLonde$age[LaLonde$treat == 0], weights = #> bal_standard$w/sum(bal_standard$w)): Selecting bandwidth *not* using 'weights' dens1 <- density(LaLonde$age[LaLonde$treat == 0], weights = bal_quant$g/sum(bal_quant$g)) #> Warning in density.default(LaLonde$age[LaLonde$treat == 0], weights = #> bal_quant$g/sum(bal_quant$g)): Selecting bandwidth *not* using 'weights' dens2 <- density(LaLonde$age[LaLonde$treat == 1]) plot(dens0, main=\"Distribution of age\", xlab=\"Age\", ylim=c(0, max(dens0$y, dens1$y))) lines(dens1, lty=2, col=\"blue\") lines(dens2, lty=3, col=\"red\") legend(\"topright\",         legend=c(\"EB\", \"DEB\", \"Treatment\"),         lty=c(1,2, 3),         col=c(\"black\", \"blue\", \"red\")) plot(x = bal_standard$w,      y = bal_quant$g,       xlab = \"EB\", ylab = \"DEB\", main = \"Comparison of EB and DEB weights\",      xlim = c(0, 3), ylim = c(0, 3))"},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/d_causal.html","id":"more-variables-all-variables","dir":"Articles","previous_headings":"ATT with entropy balancing and other methods","what":"More variables: all variables","title":"Balancing distributions for observational studies","text":"Now consider variables available LaLonde dataset. Compare re74  Compare balancing weights.  Compare estimates ATT using EB DEB. Compare QTT(0.5) using EB DEB. Compare QTT(\\(\\alpha\\)) \\(\\alpha \\\\{0.1, ..., 0.9\\}\\).","code":"bal_standard <- ebalance(LaLonde$treat,                           X = model.matrix(~ -1 + age + educ + black + hisp + married + nodegr + re74 + re75,                                            LaLonde)) #> Converged within tolerance  bal_quant <- joint_calib_att(formula_means = ~ age + educ + black + hisp + married + nodegr + re74 + re75,                               formula_quantiles = ~ age + re74 + re75,                              probs = 0.5,                               treatment =  ~ treat,                               data = LaLonde,                               method = \"eb\") bal_quant #> Weights calibrated using: eb with ebal backend. #> Summary statistics for g-weights: #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.000000 0.003086 0.013909 0.101887 0.065794 1.154954  #> Totals and precision (abs diff: 0.03793366) #>              totals    precision #> N             297.0 1.080405e-06 #> age 0.50        0.5 8.307879e-10 #> re74 0.50       0.5 1.459705e-10 #> re75 0.50       0.5 4.480694e-11 #> age          7314.0 3.147376e-05 #> educ         3083.0 1.304752e-05 #> black         238.0 5.857758e-07 #> hisp           28.0 5.359394e-08 #> married        50.0 5.735295e-07 #> nodegr        217.0 3.585783e-07 #> re74      1060586.7 1.832775e-02 #> re75       910631.2 1.955873e-02 dens0 <- density(LaLonde$re74[LaLonde$treat == 0], weights = bal_standard$w/sum(bal_standard$w)) #> Warning in density.default(LaLonde$re74[LaLonde$treat == 0], weights = #> bal_standard$w/sum(bal_standard$w)): Selecting bandwidth *not* using 'weights' dens1 <- density(LaLonde$re74[LaLonde$treat == 0], weights = bal_quant$g/sum(bal_quant$g)) #> Warning in density.default(LaLonde$re74[LaLonde$treat == 0], weights = #> bal_quant$g/sum(bal_quant$g)): Selecting bandwidth *not* using 'weights' dens2 <- density(LaLonde$re74[LaLonde$treat == 1]) plot(dens0, main=\"Distribution of re74\", xlab=\"Age\", ylim=c(0, max(dens0$y, dens1$y))) lines(dens1, lty=2, col=\"blue\") lines(dens2, lty=3, col=\"red\") legend(\"topright\",         legend=c(\"EB\", \"DEB\", \"Treatment\"),         lty=c(1,2, 3),         col=c(\"black\", \"blue\", \"red\")) plot(x = bal_standard$w,      y = bal_quant$g,       xlab = \"EB\", ylab = \"DEB\", main = \"Comparison of EB and DEB weights\",      xlim = c(0, 1.2), ylim = c(0, 1.2)) c(EB = with(LaLonde, mean(re78[treat == 1]) - weighted.mean(re78[treat == 0], bal_standard$w)),   DEB = with(LaLonde, mean(re78[treat == 1]) - weighted.mean(re78[treat == 0], bal_quant$g))) #>        EB       DEB  #> -378.4217 -392.0171 c(EB = with(LaLonde, median(re78[treat == 1]) - weightedMedian(re78[treat == 0], bal_standard$w)),   DEB = with(LaLonde, median(re78[treat == 1]) - weightedMedian(re78[treat == 0], bal_quant$g))) #>       EB      DEB  #> 72.39014 35.93408 probs_qtt <- seq(0.1, 0.9, 0.1) data.frame(   EB = with(LaLonde,              quantile(re78[treat == 1], probs_qtt) - weightedQuantile(re78[treat == 0], bal_standard$w, probs_qtt)),   DEB = with(LaLonde,              quantile(re78[treat == 1], probs_qtt) - weightedQuantile(re78[treat == 0], bal_quant$g, probs_qtt)) ) #>              EB         DEB #> 10%     0.00000     0.00000 #> 20%     0.00000     0.00000 #> 30%   788.12509   784.81613 #> 40%   265.73521   261.63315 #> 50%    72.39014    35.93408 #> 60%   156.65605   -20.31025 #> 70%  -549.49531  -669.21504 #> 80%  -498.36777  -498.36777 #> 90% -2818.06621 -2818.06621"},{"path":"https://ncn-foreigners.github.io/jointCalib/articles/d_causal.html","id":"att-with-cbps-and-dps-work-in-progress","dir":"Articles","previous_headings":"","what":"ATT with CBPS and DPS [work in progress]","title":"Balancing distributions for observational studies","text":"","code":"m0 <- CBPS(formula = treat ~ age + educ + black + hisp + married + nodegr + re74,            data = LaLonde) #> [1] \"Finding ATT with T=1 as the treatment.  Set ATT=2 to find ATT with T=0 as the treatment\" m1 <- joint_calib_cbps(formula_means = ~ age + educ + black + hisp + married + nodegr,                        formula_quantiles = ~ re74,                         probs = 0.5,                        treatment =  ~ treat,                        data = LaLonde)"},{"path":"https://ncn-foreigners.github.io/jointCalib/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Maciej Beręsewicz. Author, maintainer.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Beręsewicz M (2023). jointCalib: Joint Calibration Totals Quantiles. https://github.com/ncn-foreigners/jointCalib, https://ncn-foreigners.github.io/jointCalib/.","code":"@Manual{,   title = {jointCalib: A Joint Calibration of Totals and Quantiles},   author = {Maciej Beręsewicz},   year = {2023},   note = {https://github.com/ncn-foreigners/jointCalib, https://ncn-foreigners.github.io/jointCalib/}, }"},{"path":[]},{"path":"https://ncn-foreigners.github.io/jointCalib/index.html","id":"details","dir":"","previous_headings":"","what":"Details","title":"A Joint Calibration of Totals and Quantiles","text":"small package joint calibration totals quantiles (see Beręsewicz Szymkowiak (2023) working paper details). package combines following approaches: Deville, J. C., Särndal, C. E. (1992). Calibration estimators survey sampling. Journal American statistical Association, 87(418), 376-382. Harms, T. Duchesne, P. (2006). calibration estimation quantiles. Survey Methodology, 32(1), 37. Wu, C. (2005) Algorithms R codes pseudo empirical likelihood method survey sampling, Survey Methodology, 31(2), 239. Zhang, S., Han, P., Wu, C. (2023) Calibration Techniques Encompassing Survey Sampling, Missing Data Analysis Causal Inference, International Statistical Review 91, 165–192. allows calibrate weights known (estimated) totals quantiles jointly. backend calibration sampling (sampling::calib), laeken (laeken::calibWeights), survey (survey::grake) ebal (ebal::eb) package can used. One can also apply empirical likelihood using codes Wu (2005) support stats::constrOptim used Zhang, Han Wu (2022). Currently supports: calibration quantiles, calibration quantiles totals, calibration using standard calibration, empirical likelihood entropy balancing method, covariate distribution balancing (ATT), covariate distribution balancing propensity score (ATE). plans: generalized calibration via sampling::gencalib, calibration Gini metrics, …","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/index.html","id":"funding","dir":"","previous_headings":"","what":"Funding","title":"A Joint Calibration of Totals and Quantiles","text":"Work package supported National Science Centre, OPUS 22 grant . 2020/39/B/HS4/00941.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Joint Calibration of Totals and Quantiles","text":"can install development version jointCalib GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"ncn-foreigners/jointCalib\")"},{"path":"https://ncn-foreigners.github.io/jointCalib/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"A Joint Calibration of Totals and Quantiles","text":"Load packages","code":"library(jointCalib) library(survey) library(laeken) library(ebal)"},{"path":"https://ncn-foreigners.github.io/jointCalib/index.html","id":"example-1--census-case","dir":"","previous_headings":"Examples","what":"Example 1 – census case","title":"A Joint Calibration of Totals and Quantiles","text":"Based Haziza, D., Lesage, É. (2016). discussion weighting procedures unit nonresponse. Journal Official Statistics, 32(1), 129-145.","code":"set.seed(20230817) N <- 1000 x <- runif(N, 0, 80) #y <- 1000+10*x+rnorm(N, 0, 300) #y <- exp(-0.1 + 0.1*x) + rnorm(N, 0, 300) #y <- rbinom(N, 1, prob = 1/(exp(-0.5*(x-55))+1)) y <- 1300-(x-40)^2 + rnorm(N, 0, 300) #p <- rbinom(N, 1, prob = 0.2+0.6*(1 + exp(-5 + x/8))^-1) p <- rbinom(N, 1, prob = 0.07+0.45*(x/40-1)^2+0.0025*x) #p <- rbinom(N, 1, prob = (1.2+0.024*x)^-1) #p <- rbinom(N, 1, prob = exp(-0.2 - 0.014*x)) probs <- seq(0.1, 0.9, 0.1) quants_known <- list(x=quantile(x, probs)) totals_known <- c(x=sum(x)) df <- data.frame(x, y, p) df_resp <- df[df$p == 1, ] df_resp$d <- N/nrow(df_resp) y_quant_true <- quantile(y, probs) head(df_resp) #>           x        y p        d #> 6  12.35687 444.9053 1 3.134796 #> 7  61.90319 403.9473 1 3.134796 #> 13 60.96079 923.4975 1 3.134796 #> 14 76.85300 124.4110 1 3.134796 #> 18 71.52828 422.0934 1 3.134796 #> 19 65.32808 740.4801 1 3.134796"},{"path":"https://ncn-foreigners.github.io/jointCalib/index.html","id":"using-jointcalib-package","dir":"","previous_headings":"Examples","what":"Using jointCalib package","title":"A Joint Calibration of Totals and Quantiles","text":"example 1a: calibrate quantiles (deciles) example 1b: calibrate quantiles (deciles) can restrict weights specific range using logit. Empirical likelihood method can applied using following code Entropy balancing method can applied using following code Finally, compare method true Y distribution est_y1 – weights calibrated quantiles , est_y2 – weights calibrated quantiles totals, est_y3 – weights calibrated quantiles totals using logit distance range limitations, est_y4 – weights calibrated means using el. est_y5 – weights calibrated quantiles using el. est_y6 – weights calibrated quantiles totals using el. est_y7 – weights calibrated quantiles totals using eb. sum squares calibration totals means seems best.","code":"result1 <- joint_calib(formula_quantiles = ~x,                       data=df_resp,                       dweights=df_resp$d,                       N = N,                       pop_quantiles = quants_known,                       method = \"linear\",                       backend = \"sampling\") result1 #> Weights calibrated using: linear with sampling backend. #> Summary statistics for g-weights: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.4562  0.6773  0.8180  1.0000  1.4500  2.4538  #> Totals and precision (abs diff: 4.574665e-10) #>        totals    precision #> N       1e+03 4.557705e-10 #> x 0.10  1e-01 5.020984e-14 #> x 0.20  2e-01 1.055545e-13 #> x 0.30  3e-01 1.324496e-13 #> x 0.40  4e-01 1.580958e-13 #> x 0.50  5e-01 1.765255e-13 #> x 0.60  6e-01 1.991740e-13 #> x 0.70  7e-01 2.304823e-13 #> x 0.80  8e-01 2.882139e-13 #> x 0.90  9e-01 3.552714e-13 data.frame(true = quants_known$x, est = weightedQuantile(df_resp$x, result1$g*df_resp$d, probs)) #>          true       est #> 10%  7.078067  7.085003 #> 20% 14.831221 14.824424 #> 30% 23.146180 23.287657 #> 40% 31.641911 31.802986 #> 50% 39.033812 39.154276 #> 60% 47.527168 48.252065 #> 70% 54.984229 55.311953 #> 80% 64.073167 64.062629 #> 90% 71.565441 71.567274 result2 <- joint_calib(formula_totals = ~x,                        formula_quantiles = ~x,                        data = df_resp,                        dweights = df_resp$d,                        N = N,                        pop_quantiles = quants_known,                        pop_totals = totals_known,                        method = \"linear\",                        backend = \"sampling\") summary(result2$g) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.3563  0.6208  0.8199  1.0000  1.4368  2.5384 data.frame(true = quants_known$x, est = weightedQuantile(df_resp$x, result2$g*df_resp$d, probs)) #>          true       est #> 10%  7.078067  7.085003 #> 20% 14.831221 14.824424 #> 30% 23.146180 23.287657 #> 40% 31.641911 31.802986 #> 50% 39.033812 39.154276 #> 60% 47.527168 48.252065 #> 70% 54.984229 55.311953 #> 80% 64.073167 64.062629 #> 90% 71.565441 71.567274 result3 <- joint_calib(formula_totals = ~x,                        formula_quantiles = ~x,                        data = df_resp,                        dweights = df_resp$d,                        N = N,                        pop_quantiles = quants_known,                        pop_totals = totals_known,                        method = \"logit\",                        backend = \"sampling\",                         maxit = 500,                        bounds = c(0, 3))  summary(result3$g) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.3911  0.6254  0.8140  1.0000  1.4325  2.5186 data.frame(true = quants_known$x, est = weightedQuantile(df_resp$x, result3$g*df_resp$d, probs)) #>          true       est #> 10%  7.078067  7.085003 #> 20% 14.831221 14.824424 #> 30% 23.146180 22.872078 #> 40% 31.641911 31.297922 #> 50% 39.033812 39.154276 #> 60% 47.527168 48.252065 #> 70% 54.984229 55.311953 #> 80% 64.073167 64.529683 #> 90% 71.565441 71.567274 result4a <- joint_calib(formula_quantiles = ~ x,                         data = df_resp,                         dweights = df_resp$d,                         N = N,                         pop_quantiles = quants_known,                         method = \"el\",                         backend = \"base\") summary(result4a$g) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.4563  0.6773  0.8180  1.0000  1.4500  2.4538  result4b <- joint_calib(formula_totals = ~ x,                         formula_quantiles = ~ x,                         data = df_resp,                         dweights = df_resp$d,                         N = N,                         pop_quantiles = quants_known,                         pop_totals = totals_known,                         method = \"el\",                         backend = \"base\")  summary(result4b$g) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.4414  0.6584  0.8109  1.0000  1.4256  2.8513  result4c <- calib_el(X = result4b$Xs[, c(1, 11)],                      d = df_resp$d,                       totals = c(N,totals_known),                      maxit = 50,                      tol = 1e-8)  summary(result4c) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.7438  0.7910  0.8848  1.0000  1.2455  1.4923 data.frame(true = quants_known$x,             est = weightedQuantile(df_resp$x, result2$g*df_resp$d, probs),            est_el0 = weightedQuantile(df_resp$x, result4c*df_resp$d, probs),            est_el1 = weightedQuantile(df_resp$x, result4a$g*df_resp$d, probs),            est_el2 = weightedQuantile(df_resp$x, result4b$g*df_resp$d, probs)) #>          true       est   est_el0   est_el1   est_el2 #> 10%  7.078067  7.085003  3.640246  7.085003  7.085003 #> 20% 14.831221 14.824424  8.024948 14.824424 14.824424 #> 30% 23.146180 23.287657 14.499018 23.287657 23.287657 #> 40% 31.641911 31.802986 24.010501 31.802986 31.802986 #> 50% 39.033812 39.154276 39.154276 38.892342 39.154276 #> 60% 47.527168 48.252065 54.685438 48.252065 48.252065 #> 70% 54.984229 55.311953 63.084405 54.954054 54.954054 #> 80% 64.073167 64.062629 70.050593 64.062629 64.062629 #> 90% 71.565441 71.567274 75.663078 71.567274 71.567274 result5 <- joint_calib(formula_quantiles = ~ x,                         data = df_resp,                         dweights = df_resp$d,                         N = N,                         pop_quantiles = quants_known,                         method = \"eb\") summary(result5$g) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.4576  0.6775  0.8180  1.0003  1.4500  2.4538 results_y <- data.frame(true_y = y_quant_true,                         est_y1 = weightedQuantile(df_resp$y, result1$g * df_resp$d, probs),                         est_y2 = weightedQuantile(df_resp$y, result2$g * df_resp$d, probs),                         est_y3 = weightedQuantile(df_resp$y, result3$g * df_resp$d, probs),                         est_y4 = weightedQuantile(df_resp$y, result4c * df_resp$d, probs),                         est_y5 = weightedQuantile(df_resp$y, result4a$g * df_resp$d, probs),                         est_y6 = weightedQuantile(df_resp$y, result4b$g * df_resp$d, probs),                         est_y7 = weightedQuantile(df_resp$y, result5$g * df_resp$d, probs))  results_y #>         true_y     est_y1     est_y2     est_y3     est_y4     est_y5 #> 10%  -56.97982  -36.18473  -36.18473  -36.18473 -149.00996  -36.18473 #> 20%  210.58301  228.75429  228.75429  228.75429   17.27107  228.75429 #> 30%  444.81652  413.22517  417.60155  413.22517  203.58302  413.22517 #> 40%  646.06099  622.82192  622.82192  622.82192  381.99560  622.82192 #> 50%  803.50842  789.89936  789.89936  789.89936  503.35849  789.89936 #> 60%  975.31803  925.84730  925.84730  925.84730  679.04530  925.84730 #> 70% 1123.44643 1023.75230 1023.75230 1023.75230  811.84389 1023.75230 #> 80% 1245.62645 1162.06504 1162.06504 1162.06504 1009.46703 1162.06504 #> 90% 1449.23819 1471.33301 1471.33301 1471.33301 1242.60357 1471.33301 #>         est_y6     est_y7 #> 10%  -36.18473  -36.18473 #> 20%  228.75429  228.75429 #> 30%  411.47088  413.22517 #> 40%  622.82192  622.82192 #> 50%  789.89936  789.89936 #> 60%  925.84730  925.84730 #> 70% 1023.75230 1023.75230 #> 80% 1162.06504 1162.06504 #> 90% 1471.33301 1471.33301 apply(results_y[, -1], 2, FUN = function(x) sum((x-results_y[,1])^2)) #>    est_y1    est_y2    est_y3    est_y4    est_y5    est_y6    est_y7  #>  22342.87  22085.51  22342.87 547195.99  22342.87  22456.79  22342.87"},{"path":"https://ncn-foreigners.github.io/jointCalib/index.html","id":"using-survey-package","dir":"","previous_headings":"Examples","what":"Using survey package","title":"A Joint Calibration of Totals and Quantiles","text":"example 1a: calibrate quantiles (deciles) Calibration using calibrate Calibration using grake (low level)","code":"A <- joint_calib_create_matrix(X_q = model.matrix(~x+0, df_resp), N = N, pop_quantiles = quants_known) colnames(A) <- paste0(\"quant_\", gsub(\"\\\\D\", \"\", names(quants_known$x))) A <- as.data.frame(A) df_resp <- cbind(df_resp, A) head(df_resp) #>           x        y p        d quant_10 quant_20 quant_30 quant_40 quant_50 #> 6  12.35687 444.9053 1 3.134796        0    0.001    0.001    0.001    0.001 #> 7  61.90319 403.9473 1 3.134796        0    0.000    0.000    0.000    0.000 #> 13 60.96079 923.4975 1 3.134796        0    0.000    0.000    0.000    0.000 #> 14 76.85300 124.4110 1 3.134796        0    0.000    0.000    0.000    0.000 #> 18 71.52828 422.0934 1 3.134796        0    0.000    0.000    0.000    0.000 #> 19 65.32808 740.4801 1 3.134796        0    0.000    0.000    0.000    0.000 #>    quant_60 quant_70 quant_80 quant_90 #> 6     0.001    0.001    0.001    0.001 #> 7     0.000    0.000    0.001    0.001 #> 13    0.000    0.000    0.001    0.001 #> 14    0.000    0.000    0.000    0.000 #> 18    0.000    0.000    0.000    0.001 #> 19    0.000    0.000    0.000    0.001 m1 <- svydesign(ids = ~1, data = df_resp, weights = ~d) quants_formula <- as.formula(paste(\"~\", paste(colnames(A), collapse = \"+\"))) quants_formula #> ~quant_10 + quant_20 + quant_30 + quant_40 + quant_50 + quant_60 +  #>     quant_70 + quant_80 + quant_90 svytotal(quants_formula, m1) #>            total     SE #> quant_10 0.10972 0.0175 #> quant_20 0.23197 0.0237 #> quant_30 0.29154 0.0255 #> quant_40 0.34796 0.0267 #> quant_50 0.38871 0.0273 #> quant_60 0.43887 0.0278 #> quant_70 0.50784 0.0280 #> quant_80 0.63323 0.0270 #> quant_90 0.78100 0.0232 pop_totals <- c(N, probs) names(pop_totals) <- c(\"(Intercept)\", colnames(A)) m1_cal <- calibrate(m1, quants_formula, pop_totals) svytotal(quants_formula, m1_cal) #>          total SE #> quant_10   0.1  0 #> quant_20   0.2  0 #> quant_30   0.3  0 #> quant_40   0.4  0 #> quant_50   0.5  0 #> quant_60   0.6  0 #> quant_70   0.7  0 #> quant_80   0.8  0 #> quant_90   0.9  0 g1 <- grake(mm = as.matrix(cbind(1, A)),             ww = df_resp$d,             calfun = cal.linear,             population = pop_totals,             bounds = list(lower = -Inf, upper = Inf),             epsilon = 1e-7,             verbose = FALSE,             maxit = 50,             variance = NULL) summary(as.numeric(g1)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.4562  0.6773  0.8180  1.0000  1.4500  2.4538"},{"path":[]},{"path":[]},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/calib_el.html","id":null,"dir":"Reference","previous_headings":"","what":"An internal function for calibration of weights using empirical likelihood method — calib_el","title":"An internal function for calibration of weights using empirical likelihood method — calib_el","text":"calib_el performs calibration using empirical likelihood (EL) method. function taken Wu (2005). algorithm problem convergence constrOptim used instead (Zhang, Han Wu (2022)). (pseudo) EL following (pseudo) EL function maximized \\[\\sum_{\\r} d_i\\log(p_i),\\] following constraint \\[\\sum_{\\r} p_i = 1,\\] constraints quantiles (notation Harms Duchesne (2006)) \\[\\sum_{\\r} p_i(a_{} - \\alpha/N) = 0,\\] \\(a_{}\\) created using joint_calib_create_matrix function, possibly means \\[\\sum_{\\r} p_i(x_{} - \\mu_{x}) = 0,\\] \\(\\mu_{x}\\) known population mean X. simplicity notation assume one quantile one mean known. can generalized multiple quantiles means.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/calib_el.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An internal function for calibration of weights using empirical likelihood method — calib_el","text":"","code":"calib_el(   X,   d,   totals,   maxit = 50,   tol = 1e-08,   eps = .Machine$double.eps,   att = FALSE,   ... )"},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/calib_el.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"An internal function for calibration of weights using empirical likelihood method — calib_el","text":"X matrix variables calibration quantiles totals (first column intercept), d initial d-weights calibration (e.g. design-weights), totals vector totals (1 element population size), maxit numeric value giving maximum number iterations, tol desired accuracy iterative procedure, eps desired accuracy computing Moore-Penrose generalized inverse (see MASS::ginv()), att indicating whether weights sum treatment group (joint_calib_att function), ... arguments passed stats::optim via stats::constrOptim.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/calib_el.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"An internal function for calibration of weights using empirical likelihood method — calib_el","text":"Returns vector empirical likelihood g-weights","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/calib_el.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"An internal function for calibration of weights using empirical likelihood method — calib_el","text":"Wu, C. (2005). Algorithms R codes pseudo empirical likelihood method survey sampling. Survey Methodology, 31(2), 239 (code taken https://sas.uwaterloo.ca/~cbwu/Rcodes/LagrangeM2.txt). Zhang, S., Han, P., Wu, C. (2023) Calibration Techniques Encompassing Survey Sampling, Missing Data Analysis Causal Inference. International Statistical Review, 91: 165–192. https://doi.org/10.1111/insr.12518 (code taken Supplementary Materials).","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/calib_el.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"An internal function for calibration of weights using empirical likelihood method — calib_el","text":"Maciej Beręsewicz based Wu (2005) Zhang, Han Wu (2022)","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/calib_el.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"An internal function for calibration of weights using empirical likelihood method — calib_el","text":"","code":"## generate data based on Haziza and Lesage (2016) set.seed(123) N <- 1000 x <- runif(N, 0, 80) y <- exp(-0.1 + 0.1*x) + rnorm(N, 0, 300) p <- rbinom(N, 1, prob = exp(-0.2 - 0.014*x)) totals_known <- c(N=N, x=sum(x)) df <- data.frame(x, y, p) df_resp <- df[df$p == 1, ] df_resp$d <- N/nrow(df_resp) res <- calib_el(X = model.matrix(~x, df_resp),                 d = df_resp$d,                 totals = totals_known) data.frame(known = totals_known, estimated=colSums(res*df_resp$d*model.matrix(~x, df_resp))) #>      known estimated #> N  1000.00   1000.00 #> x 39782.22  39782.22"},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/control_calib.html","id":null,"dir":"Reference","previous_headings":"","what":"control parameters — control_calib","title":"control parameters — control_calib","text":"control_calib function contains control parameters joint_calib_create_matrix","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/control_calib.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"control parameters — control_calib","text":"","code":"control_calib(   interpolation = c(\"logit\", \"linear\"),   logit_const = -1000,   sum_to_sample = FALSE,   sum_to_one = FALSE,   survey_sparse = FALSE,   ebal_constraint_tolerance = 1,   ebal_print_level = 0,   el_att = FALSE )"},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/control_calib.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"control parameters — control_calib","text":"interpolation type interpolation: logit linear, logit_const constant logit interpolation, sum_to_sample whether weights sum sample, sum_to_one whether weights sum one (aka normalized weights), survey_sparse whether use sparse matrices via Matrix package survey::grake() (currently supported), ebal_constraint_tolerance tolerance level used ebalance decide moments reweighted data equal target moments (see ebal::ebalance()), ebal_print_level controls level printing: 0 (normal printing), 2 (detailed), 3 (detailed) (see ebal::ebalance()), el_att whether weights control sum treatment size (calib_el function ).","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/control_calib.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"control parameters — control_calib","text":"list parameters","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/control_calib.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"control parameters — control_calib","text":"Maciej Beręsewicz","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib.html","id":null,"dir":"Reference","previous_headings":"","what":"Function for the joint calibration of totals and quantiles — joint_calib","title":"Function for the joint calibration of totals and quantiles — joint_calib","text":"joint_calib allows joint calibration totals quantiles. provides user-friendly interface includes specification variables formula notation, vector population totals, list quantiles, variety backends methods.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function for the joint calibration of totals and quantiles — joint_calib","text":"","code":"joint_calib(   formula_totals = NULL,   formula_quantiles = NULL,   data = NULL,   dweights = NULL,   N = NULL,   pop_totals = NULL,   pop_quantiles = NULL,   subset = NULL,   backend = c(\"sampling\", \"laeken\", \"survey\", \"ebal\", \"base\"),   method = c(\"raking\", \"linear\", \"logit\", \"sinh\", \"truncated\", \"el\", \"eb\"),   bounds = c(0, 10),   maxit = 50,   tol = 1e-08,   eps = .Machine$double.eps,   control = control_calib(),   ... )"},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function for the joint calibration of totals and quantiles — joint_calib","text":"formula_totals formula variables calibrate totals, formula_quantiles formula variables quantile calibration, data data.frame variables, dweights initial d-weights calibration (e.g. design weights), N population size calibration quantiles, pop_totals named vector population totals formula_totals. provided exactly survey package (see survey::calibrate), pop_quantiles named list population quantiles formula_quantiles newsvyquantile class object (survey::svyquantile function), subset formula subset data, backend specify R package perform calibration. sampling, laeken, survey, ebal base allowed, method specify method (.e. distance function) calibration. raking, linear, logit, sinh, truncated, el (empirical likelihood), eb (entropy balancing) allowed, bounds numeric vector length two giving bounds g-weights, maxit numeric value representing maximum number iterations, tol desired accuracy iterative procedure (sampling, laeken, ebal, el) tolerance matching population total survey::grake (see help survey::grake) eps desired accuracy computing Moore-Penrose generalized inverse (see MASS::ginv()) control list control parameters (currently joint_calib_create_matrix) ... arguments passed either sampling::calib, laeken::calibWeights, survey::calibrate optim::constrOptim","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function for the joint calibration of totals and quantiles — joint_calib","text":"Returns list containing: g -- g-weight sums sample size, Xs -- matrix used calibration (.e. Intercept, X X_q transformed calibration quantiles), totals -- vector totals (.e. N, pop_totals pop_quantiles), method -- selected method, backend -- selected backend.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Function for the joint calibration of totals and quantiles — joint_calib","text":"Imports function","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function for the joint calibration of totals and quantiles — joint_calib","text":"Beręsewicz,  M., Szymkowiak, M. (2023). note joint calibration estimators totals quantiles Arxiv preprint https://arxiv.org/abs/2308.13281 Deville, J. C., Särndal, C. E. (1992). Calibration estimators survey sampling. Journal American statistical Association, 87(418), 376-382. Harms, T. Duchesne, P. (2006). calibration estimation quantiles. Survey Methodology, 32(1), 37. Wu, C. (2005) Algorithms R codes pseudo empirical likelihood method survey sampling, Survey Methodology, 31(2), 239. Zhang, S., Han, P., Wu, C. (2023) Calibration Techniques Encompassing Survey Sampling, Missing Data Analysis Causal Inference, International Statistical Review 91, 165–192. Haziza, D., Lesage, É. (2016). discussion weighting procedures unit nonresponse. Journal Official Statistics, 32(1), 129-145.","code":""},{"path":[]},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function for the joint calibration of totals and quantiles — joint_calib","text":"Maciej Beręsewicz","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function for the joint calibration of totals and quantiles — joint_calib","text":"","code":"## generate data based on Haziza and Lesage (2016) set.seed(123) N <- 1000 x <- runif(N, 0, 80) y <- exp(-0.1 + 0.1*x) + rnorm(N, 0, 300) p <- rbinom(N, 1, prob = exp(-0.2 - 0.014*x)) probs <- seq(0.1, 0.9, 0.1) quants_known <- list(x=quantile(x, probs)) totals_known <- c(x=sum(x)) df <- data.frame(x, y, p) df_resp <- df[df$p == 1, ] df_resp$d <- N/nrow(df_resp) y_quant_true <- quantile(y, probs) ## standard calibration for comparison result0 <- sampling::calib(Xs = cbind(1, df_resp$x),                            d = df_resp$d,                            total = c(N, totals_known),                            method = \"linear\")  y_quant_hat0 <- laeken::weightedQuantile(x = df_resp$y,                                          probs = probs,                                          weights = result0*df_resp$d) x_quant_hat0 <- laeken::weightedQuantile(x = df_resp$x,                                          probs = probs,                                          weights = result0*df_resp$d)  ## example 1: calibrate only quantiles (deciles) result1 <- joint_calib(formula_quantiles = ~x,                        data = df_resp,                        dweights = df_resp$d,                        N = N,                        pop_quantiles = quants_known,                        method = \"linear\",                        backend = \"sampling\") ## estimate quantiles y_quant_hat1 <- laeken::weightedQuantile(x = df_resp$y,                                          probs = probs,                                          weights = result1$g*df_resp$d) x_quant_hat1 <- laeken::weightedQuantile(x = df_resp$x,                                          probs = probs,                                          weights = result1$g*df_resp$d)  ## compare with known data.frame(standard = y_quant_hat0, est=y_quant_hat1, true=y_quant_true) #>      standard        est       true #> 10% -284.3574 -285.34675 -292.97255 #> 20% -131.7079 -131.70792 -128.19010 #> 30%  -25.2815  -19.50460  -10.07312 #> 40%   80.5919   84.23786   84.64057 #> 50%  175.5490  178.96015  184.87445 #> 60%  274.0404  279.73343  294.76788 #> 70%  412.2826  426.98679  453.35435 #> 80%  592.0840  606.73082  669.36570 #> 90% 1105.6883 1172.38891 1163.92646  ## example 2: calibrate with quantiles (deciles) and totals result2 <- joint_calib(formula_totals = ~x,                        formula_quantiles = ~x,                        data = df_resp,                        dweights = df_resp$d,                        N = N,                        pop_quantiles = quants_known,                        pop_totals = totals_known,                        method = \"linear\",                        backend = \"sampling\") ## estimate quantiles y_quant_hat2 <- laeken::weightedQuantile(x = df_resp$y,                                          probs = probs,                                          weights = result2$g*df_resp$d) x_quant_hat2 <- laeken::weightedQuantile(x = df_resp$x,                                          probs = probs,                                          weights = result2$g*df_resp$d)  ## compare with known data.frame(standard = y_quant_hat0, est1=y_quant_hat1,            est2=y_quant_hat2, true=y_quant_true) #>      standard       est1       est2       true #> 10% -284.3574 -285.34675 -285.34675 -292.97255 #> 20% -131.7079 -131.70792 -131.70792 -128.19010 #> 30%  -25.2815  -19.50460  -21.94192  -10.07312 #> 40%   80.5919   84.23786   84.23786   84.64057 #> 50%  175.5490  178.96015  178.96015  184.87445 #> 60%  274.0404  279.73343  279.73343  294.76788 #> 70%  412.2826  426.98679  426.98679  453.35435 #> 80%  592.0840  606.73082  606.73082  669.36570 #> 90% 1105.6883 1172.38891 1172.38891 1163.92646  ## example 3: calibrate wigh quantiles (deciles) and totals with ## hyperbolic sinus (sinh) and survey package  result3 <- joint_calib(formula_totals = ~x,                        formula_quantiles = ~x,                        data = df_resp,                        dweights = df_resp$d,                        N = N,                        pop_quantiles = quants_known,                        pop_totals = totals_known,                        method = \"sinh\",                        backend = \"survey\")  ## estimate quantiles y_quant_hat3 <- laeken::weightedQuantile(x = df_resp$y,                                          probs = probs,                                          weights = result3$g*df_resp$d) x_quant_hat3 <- laeken::weightedQuantile(x = df_resp$x,                                          probs = probs,                                          weights = result3$g*df_resp$d)  ## example 4: calibrate wigh quantiles (deciles) and totals with ebal package result4 <- joint_calib(formula_totals = ~x,                        formula_quantiles = ~x,                        data = df_resp,                        dweights = df_resp$d,                        N = N,                        pop_quantiles = quants_known,                        pop_totals = totals_known,                        method = \"eb\",                        backend = \"ebal\")  ## estimate quantiles y_quant_hat4 <- laeken::weightedQuantile(x = df_resp$y,                                          probs = probs,                                          weights = result4$g*df_resp$d) x_quant_hat4 <- laeken::weightedQuantile(x = df_resp$x,                                          probs = probs,                                          weights = result4$g*df_resp$d)  ## compare with known data.frame(standard = y_quant_hat0,            est1=y_quant_hat1,            est2=y_quant_hat2,            est3=y_quant_hat3,            est4=y_quant_hat4,            true=y_quant_true) #>      standard       est1       est2       est3       est4       true #> 10% -284.3574 -285.34675 -285.34675 -285.34675 -285.34675 -292.97255 #> 20% -131.7079 -131.70792 -131.70792 -131.70792 -131.70792 -128.19010 #> 30%  -25.2815  -19.50460  -21.94192  -21.94192  -21.94192  -10.07312 #> 40%   80.5919   84.23786   84.23786   84.23786   84.23786   84.64057 #> 50%  175.5490  178.96015  178.96015  178.96015  178.96015  184.87445 #> 60%  274.0404  279.73343  279.73343  279.73343  279.73343  294.76788 #> 70%  412.2826  426.98679  426.98679  426.98679  426.98679  453.35435 #> 80%  592.0840  606.73082  606.73082  606.73082  606.73082  669.36570 #> 90% 1105.6883 1172.38891 1172.38891 1172.38891 1172.38891 1163.92646 ## compare with known X data.frame(standard = x_quant_hat0,            est1=x_quant_hat1,            est2=x_quant_hat2,            est3=x_quant_hat3,            est4=x_quant_hat4,            true = quants_known$x) #>     standard     est1     est2     est3     est4      true #> 10%  8.43342  8.08468  8.08468  8.08468  8.08468  8.081984 #> 20% 17.37948 16.27337 16.27337 16.27337 16.15962 16.250618 #> 30% 24.62111 24.32420 24.32420 24.09831 24.09831 24.231978 #> 40% 32.71552 31.67142 31.67142 31.67142 31.65285 31.663990 #> 50% 39.54339 39.18696 39.18696 39.18696 39.18696 39.196020 #> 60% 47.19213 47.53136 47.53136 47.44365 47.44365 47.469023 #> 70% 54.91923 55.60166 55.60166 55.45591 55.45591 55.499635 #> 80% 60.96227 63.90653 63.90653 63.90653 63.90653 63.906013 #> 90% 70.81061 71.60363 71.60363 71.12172 71.12172 71.338558"},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_att.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to balance the covariate distributions of a control and treatment group using joint_calib — joint_calib_att","title":"Function to balance the covariate distributions of a control and treatment group using joint_calib — joint_calib_att","text":"joint_calib_att allows quantile mean quantile balancing covariate distributions control treatment groups. provides user-friendly interface specifying variables quantiles balanced. joint_calib_att uses joint_calib function, user can apply different methods find weights balance control treatment groups. details see joint_calib() Beręsewicz Szymkowiak (2023) working paper.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_att.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to balance the covariate distributions of a control and treatment group using joint_calib — joint_calib_att","text":"","code":"joint_calib_att(   formula_means = NULL,   formula_quantiles = NULL,   treatment = NULL,   data,   probs = c(0.25, 0.5, 0.75),   ... )"},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_att.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to balance the covariate distributions of a control and treatment group using joint_calib — joint_calib_att","text":"formula_means formula variables balanced means, formula_quantiles formula variables balanced quantiles, treatment formula treatment indicator, data data.frame variables, probs vector named list quantiles balanced (default c(0.25, 0.5, 0.75)), ... parameters passed joint_calib function.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_att.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to balance the covariate distributions of a control and treatment group using joint_calib — joint_calib_att","text":"Returns list containing: g -- g-weight sums treatment group size, Xs -- matrix used balancing (.e. Intercept, X based formula_means X_q transformed balancing quantiles based formula_quantiles probs), totals -- vector treatment reference size (N), means (pop_totals) order quantiles (based formula_quantiles probs). method -- selected method, backend -- selected backend.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_att.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to balance the covariate distributions of a control and treatment group using joint_calib — joint_calib_att","text":"Beręsewicz, M. Szymkowiak, M. (2023) note joint calibration estimators totals quantiles Arxiv preprint https://arxiv.org/abs/2308.13281 Greifer N (2023). WeightIt: Weighting Covariate Balance Observational Studies. R package version 0.14.2, https://CRAN.R-project.org/package=WeightIt. Greifer N (2023). cobalt: Covariate Balance Tables Plots. R package version 4.5.1, https://CRAN.R-project.org/package=cobalt. Ho, D., Imai, K., King, G., Stuart, E. . (2011). MatchIt: Nonparametric Preprocessing Parametric Causal Inference. Journal Statistical Software, 42(8), 1–28. https://doi.org/10.18637/jss.v042.i08 Xu, Y., Yang, E. (2023). Hierarchically Regularized Entropy Balancing. Political Analysis, 31(3), 457-464. https://doi.org/10.1017/pan.2022.12","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_att.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to balance the covariate distributions of a control and treatment group using joint_calib — joint_calib_att","text":"Maciej Beręsewicz","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_att.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to balance the covariate distributions of a control and treatment group using joint_calib — joint_calib_att","text":"","code":"## generate data as in the hbal package set.seed(123) N <- 1500 X1 <- rnorm(N) X2 <- rnorm(N) X3 <- rbinom(N, size = 1, prob = .5) X1X3 <- X1*X3 D_star <- 0.5*X1 + 0.3*X2 + 0.2*X1*X2 - 0.5*X1*X3 -1 D <- ifelse(D_star > rnorm(N), 1, 0) y <- 0.5*D + X1 + X2 + X2*X3 + rnorm(N) dat <- data.frame(D = D, X1 = X1, X2 = X2, X3 = X3, X1X3=X1X3, Y = y) head(dat) #>   D          X1         X2 X3       X1X3           Y #> 1 0 -0.56047565 -0.8209867  0 0.00000000 -1.83035284 #> 2 0 -0.23017749 -0.3072572  0 0.00000000 -1.24711079 #> 3 0  1.55870831 -0.9020980  0 0.00000000 -0.80059376 #> 4 0  0.07050839  0.6270687  1 0.07050839 -0.09295057 #> 5 0  0.12928774  1.1203550  0 0.00000000  0.98562207 #> 6 0  1.71506499  2.1272136  1 1.71506499  7.22227890  ## Balancing means of X1, X2 and X3 and quartiles (0.25, 0.5, 0.75) of X1 and X2 ## sampling::raking is used results <- joint_calib_att( formula_means = ~ X1 + X2 + X3, formula_quantiles = ~ X1 + X2, treatment = ~ D, data = dat, method = \"raking\" )  ## Results are presented with summary statistics of balance weights (g-weights) ## and information on the accuracy of reproducing reference treatment distributions results #> Weights calibrated using: raking with sampling backend. #> Summary statistics for g-weights: #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.004337 0.078634 0.151831 0.221498 0.293544 1.957529  #> Totals and precision (abs diff: 9.097514e-06) #>           totals     precision #> N       272.0000  4.706215e-06 #> X1 0.25   0.2500  9.885191e-09 #> X1 0.50   0.5000  1.235785e-08 #> X1 0.75   0.7500  1.436596e-08 #> X2 0.25   0.2500  9.738133e-09 #> X2 0.50   0.5000  1.221405e-08 #> X2 0.75   0.7500  1.402932e-08 #> X1      123.2252 -9.227300e-07 #> X2      130.8188 -1.066397e-06 #> X3      126.0000  2.329582e-06  ## An interaction between X1 and X2 is added to means results2 <- joint_calib_att( formula_means = ~ X1 + X2 + X3 + X1*X3, formula_quantiles = ~ X1 + X2, treatment = ~ D, data = dat, method = \"raking\" )  ## Results with interaction are presented below results2 #> Weights calibrated using: raking with sampling backend. #> Summary statistics for g-weights: #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.002461 0.073372 0.145635 0.221498 0.283639 2.411691  #> Totals and precision (abs diff: 2.003603e-05) #>            totals     precision #> N       272.00000  1.115847e-05 #> X1 0.25   0.25000  2.759414e-08 #> X1 0.50   0.50000  3.246100e-08 #> X1 0.75   0.75000  3.614879e-08 #> X2 0.25   0.25000  2.113723e-08 #> X2 0.50   0.50000  2.837084e-08 #> X2 0.75   0.75000  3.410142e-08 #> X1      123.22524 -3.321686e-06 #> X2      130.81875 -1.204567e-06 #> X3      126.00000  3.198817e-06 #> X1:X3    23.06458 -9.726806e-07  ## As noted in the documentation, the probs argument can be a named list of different orders ## In this example, we specify that X1 should be balanced at the mean, ## while X2 should be balanced at Q1 and Q3 results3 <- joint_calib_att( formula_means = ~ X1 + X2 + X3 + X1*X3, formula_quantiles = ~ X1 + X2, treatment = ~ D, data = dat, method = \"raking\", probs = list(X1 = 0.5, X2 = c(0.25, 0.75)) )  ## Results with different orders are presented below results3 #> Weights calibrated using: raking with sampling backend. #> Summary statistics for g-weights: #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.003475 0.076911 0.145924 0.221498 0.278003 2.779197  #> Totals and precision (abs diff: 5.695273e-06) #>            totals     precision #> N       272.00000  3.214904e-06 #> X1 0.50   0.50000  7.916963e-09 #> X2 0.25   0.25000  8.242246e-09 #> X2 0.75   0.75000  1.067702e-08 #> X1      123.22524  3.830925e-08 #> X2      130.81875 -1.362999e-06 #> X3      126.00000  1.025260e-06 #> X1:X3    23.06458 -2.696433e-08  ## Finally, we specify an order of quantile for the interaction results4 <- joint_calib_att( formula_means = ~ X1 + X2 + X3, formula_quantiles = ~ X1 + X2 + X1:X3, treatment = ~ D, data = dat, probs = list(X1=0.5, X2 = c(0.25, 0.5), `X1:X3` = 0.75), method = \"raking\" )  ## Results with Q3 balancing for interaction are presented below results4 #> Weights calibrated using: raking with sampling backend. #> Summary statistics for g-weights: #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.008147 0.083688 0.149140 0.221498 0.276006 2.340755  #> Totals and precision (abs diff: 1.554366e-06) #>              totals     precision #> N          272.0000  7.408541e-07 #> X1 0.50      0.5000  1.721413e-09 #> X2 0.25      0.2500  2.127525e-09 #> X2 0.50      0.5000  2.367036e-09 #> X1:X3 0.75   0.7500  2.147864e-09 #> X1         123.2252  2.995701e-08 #> X2         130.8188 -3.915528e-07 #> X3         126.0000  3.836380e-07"},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_cbps.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to balance the covariate distributions using covariate balancing propensity score CBPS — joint_calib_cbps","title":"Function to balance the covariate distributions using covariate balancing propensity score CBPS — joint_calib_cbps","text":"joint_calib_cbps allows quantile mean quantile balancing covariate distributions control treatment groups using covariate balancing propensity score method (Imai & Ratkovic (2014)). CBPS::CBPS() CBPS::hdCBPS() used backend estimating parameters. function works similar way joint_calib_att() function, .e. user can specify variables balancing means well quantiles.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_cbps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to balance the covariate distributions using covariate balancing propensity score CBPS — joint_calib_cbps","text":"","code":"joint_calib_cbps(   formula_means = NULL,   formula_quantiles = NULL,   treatment = NULL,   data,   probs = c(0.25, 0.5, 0.75),   control = control_calib(),   standardize = FALSE,   method = \"exact\",   variable_selection = FALSE,   target = NULL,   ... )"},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_cbps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to balance the covariate distributions using covariate balancing propensity score CBPS — joint_calib_cbps","text":"formula_means formula variables balanced means, formula_quantiles formula variables balanced quantiles, treatment formula treatment indicator, data data.frame variables, probs vector named list quantiles balanced (default c(0.25, 0.5, 0.75)), control control list parameters creation X_q matrix based formula_quantiles probs (see joint_calib_create_matrix()), standardize default FALSE, normalizes weights sum 1 within treatment group (passed CBPS() function), method default \"exact\". Choose \"\" fit -identified model combines propensity score covariate balancing conditions; choose \"exact\" fit model contains covariate balancing conditions (passed CBPS() function) variable_selection default FALSE. Set TRUE select high dimension CBPS via CBPS::hdCBPS(), target specify target (y) variable hdCBPS function, ... parameters passed CBPS hdCBPS functions.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_cbps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to balance the covariate distributions using covariate balancing propensity score CBPS — joint_calib_cbps","text":"Returns CBPS list object result hdCBPS function.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_cbps.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Function to balance the covariate distributions using covariate balancing propensity score CBPS — joint_calib_cbps","text":"Imports function","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_cbps.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to balance the covariate distributions using covariate balancing propensity score CBPS — joint_calib_cbps","text":"Imai, K., Ratkovic, M. (2014). Covariate balancing propensity score. Journal Royal Statistical Society Series B: Statistical Methodology, 76(1), 243-263. Fong C, Ratkovic M, Imai K (2022). CBPS: Covariate Balancing Propensity Score. R package version 0.23, https://CRAN.R-project.org/package=CBPS.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_cbps.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to balance the covariate distributions using covariate balancing propensity score CBPS — joint_calib_cbps","text":"Maciej Beręsewicz","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_cbps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to balance the covariate distributions using covariate balancing propensity score CBPS — joint_calib_cbps","text":"","code":"## generate data as in the hbal package (see [hbal::hbal()]) set.seed(123) N <- 1500 X1 <- rnorm(N) X2 <- rnorm(N) X3 <- rbinom(N, size = 1, prob = .5) X1X3 <- X1*X3 D_star <- 0.5*X1 + 0.3*X2 + 0.2*X1*X2 - 0.5*X1*X3 - 1 D <- ifelse(D_star > rnorm(N), 1, 0) # Treatment indicator y <- 0.5*D + X1 + X2 + X2*X3 + rnorm(N) # Outcome dat <- data.frame(D = D, X1 = X1, X2 = X2, X3 = X3, X1X3 = X1X3, Y = y) head(dat) #>   D          X1         X2 X3       X1X3           Y #> 1 0 -0.56047565 -0.8209867  0 0.00000000 -1.83035284 #> 2 0 -0.23017749 -0.3072572  0 0.00000000 -1.24711079 #> 3 0  1.55870831 -0.9020980  0 0.00000000 -0.80059376 #> 4 0  0.07050839  0.6270687  1 0.07050839 -0.09295057 #> 5 0  0.12928774  1.1203550  0 0.00000000  0.98562207 #> 6 0  1.71506499  2.1272136  1 1.71506499  7.22227890  ## Balancing means of X1, X2 and X3 and quartiles (0.25, 0.5, 0.75) of X1 and X2. result <- joint_calib_cbps(formula_means = ~ X1 + X2 + X3,                            formula_quantiles = ~ X1 + X2,                            treatment = ~ D,                            data = dat)  ## CBPS output is presented result #>  #> Call:  CBPS::CBPS(formula = stats::as.formula(paste(names(Xs)[1], \"~ .\")),  #>     data = Xs, ATT = 0, standardize = standardize, method = method) #>  #> Coefficients: #>              Treated   #> (Intercept)   -3.33937 #> X1             0.96194 #> X2             1.16056 #> X3            -0.04035 #> X1.25        151.98431 #> X1.50         24.80205 #> X1.75        129.06492 #> X2.25        111.06168 #> X2.50         78.79001 #> X2.75        161.70110 #> Residual Deviance:\t 1274  #> J-Statistic:\t\t\t 0.0171219  #> Log-Likelihood:\t  -636.7567   ## calculate ATE by hand w_1 <- dat$D/fitted(result) w_1 <- w_1/mean(w_1) w_0 <- (1-dat$D)/(1-fitted(result)) w_0 <- w_0/mean(w_0) mean((w_1-w_0)*dat$Y) #> [1] 0.3557789  ## Compare with standard CBPS using only means result2 <- CBPS::CBPS(D ~ X1 + X2 + X3, data = dat, method = \"exact\", standardize = FALSE, ATT = 0)  ## calculate ATE by hand w_1a <- dat$D/fitted(result2) w_1a <- w_1a/mean(w_1a) w_0a <- (1-dat$D)/(1-fitted(result2)) w_0a <- w_0a/mean(w_0a) mean((w_1a-w_0a)*dat$Y) #> [1] 0.3348222"},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_create_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"An internal function to create an A matrix for calibration of quantiles — joint_calib_create_matrix","title":"An internal function to create an A matrix for calibration of quantiles — joint_calib_create_matrix","text":"joint_calib_create_matrix function creates \\(= [a_{ij}]\\) matrix calibration quantiles. Function allows create matrix using logistic interpolation (using stats::plogis, default) linear (Harms Duchesne (2006), .e. slightly modified Heavyside function). case logistic interpolation elements \\(\\) created follows \\[a_{j} = \\frac{1}{(1 + \\exp\\left(-2l\\left(x_{ij}-Q_{x_j, \\alpha}\\right)\\right))N},\\] \\(x_{ij}\\) \\(\\)th row auxiliary variable \\(X_j\\), \\(N\\) population size, \\(Q_{x_j, \\alpha}\\) known population \\(\\alpha\\)th quantile, \\(l\\) set -1000 (default). case  linear interpolation elements \\(\\) created follows \\[a_{j}= \\begin{cases} N^{-1}, &  x_{j} \\leqslant L_{x_{j}, r} \\left(Q_{x_j, \\alpha}\\right), \\cr N^{-1} \\beta_{x_{j}, r}\\left(Q_{x_j, \\alpha}\\right), & x_{j}=U_{x_{j}, r}\\left(Q_{x_j, \\alpha}\\right), \\cr 0, & x_{j}>U_{x_{j}, r} \\left(Q_{x_j, \\alpha}\\right), \\end{cases}\\] \\(=1,...,r\\), \\(j=1,...,k\\), \\(r\\) set respondents, \\(k\\) auxiliary variable index \\[L_{x_{j}, r}(t) = \\max \\left\\lbrace\\left\\lbrace{x_{j}}, \\s \\mid x_{j} \\leqslant t\\right\\rbrace \\cup \\lbrace-\\infty\\rbrace \\right\\rbrace,\\] \\[U_{x_{j}, r}(t) = \\min \\left\\lbrace\\left\\lbrace{x_{j}}, \\s \\mid x_{j}>t\\right\\rbrace \\cup \\lbrace\\infty\\rbrace \\right\\rbrace,\\] \\[\\beta_{x_{j}, r}(t) = \\frac{t-L_{x_{j}, s}(t)}{U_{x_{j}, s}(t)-L_{x_{j}, s}(t)},\\] \\(=1,...,r\\), \\(j=1,...,k\\), \\(t \\\\mathbb{R}\\).","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_create_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An internal function to create an A matrix for calibration of quantiles — joint_calib_create_matrix","text":"","code":"joint_calib_create_matrix(X_q, N, pop_quantiles, control = control_calib())"},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_create_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"An internal function to create an A matrix for calibration of quantiles — joint_calib_create_matrix","text":"X_q matrix variables calibration quantiles, N population size calibration quantiles, pop_quantiles vector population quantiles X_q, control control parameter creation X_q matrix.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_create_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"An internal function to create an A matrix for calibration of quantiles — joint_calib_create_matrix","text":"Return matrix ","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_create_matrix.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"An internal function to create an A matrix for calibration of quantiles — joint_calib_create_matrix","text":"Harms, T. Duchesne, P. (2006). calibration estimation quantiles. Survey Methodology, 32(1), 37.","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_create_matrix.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"An internal function to create an A matrix for calibration of quantiles — joint_calib_create_matrix","text":"Maciej Beręsewicz","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/reference/joint_calib_create_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"An internal function to create an A matrix for calibration of quantiles — joint_calib_create_matrix","text":"","code":"# Create matrix for one variable and 3 quantiles set.seed(123) N <- 1000 x <- as.matrix(rnorm(N)) quants <- list(quantile(x, c(0.25,0.5,0.75))) A <- joint_calib_create_matrix(x, N, quants) head(A) #>               [,1]         [,2]  [,3] #> [1,]  3.417662e-33 1.000000e-03 0.001 #> [2,] 1.221974e-176 1.000000e-03 0.001 #> [3,]  0.000000e+00 0.000000e+00 0.000 #> [4,] 3.168423e-307 2.389406e-30 0.001 #> [5,]  0.000000e+00 7.091618e-56 0.001 #> [6,]  0.000000e+00 0.000000e+00 0.000 colSums(A) #> [1] 0.2502323 0.4999654 0.7498815  # Create matrix with linear interpolation A <- joint_calib_create_matrix(x, N, quants, control_calib(interpolation=\"linear\")) head(A) #>      [,1]  [,2]  [,3] #> [1,]    0 0.001 0.001 #> [2,]    0 0.001 0.001 #> [3,]    0 0.000 0.000 #> [4,]    0 0.000 0.001 #> [5,]    0 0.000 0.001 #> [6,]    0 0.000 0.000 colSums(A) #> [1] 0.24975 0.49950 0.74925  # Create matrix for two variables and different number of quantiles  set.seed(123) x1 <- rnorm(N) x2 <- rchisq(N, 1) x <- cbind(x1, x2) quants <- list(quantile(x1, 0.5), quantile(x2, c(0.1, 0.75, 0.9))) B <- joint_calib_create_matrix(x, N, quants) head(B) #>              [,1]          [,2]          [,3]  [,4] #> [1,] 1.000000e-03  7.889542e-30  1.000000e-03 0.001 #> [2,] 1.000000e-03 1.614292e-242  1.000000e-03 0.001 #> [3,] 0.000000e+00  0.000000e+00  0.000000e+00 0.001 #> [4,] 2.389406e-30  0.000000e+00  0.000000e+00 0.000 #> [5,] 7.091618e-56  0.000000e+00 1.360616e-132 0.001 #> [6,] 0.000000e+00  0.000000e+00  1.000000e-03 0.001 colSums(B) #> [1] 0.49996541 0.09961593 0.74980652 0.89987264"},{"path":[]},{"path":"https://ncn-foreigners.github.io/jointCalib/news/index.html","id":"jointcalib-012","dir":"Changelog","previous_headings":"","what":"jointCalib 0.1.2","title":"jointCalib 0.1.2","text":"initial version vignette theory bug fix joint_calib_cbps","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/news/index.html","id":"jointcalib-011","dir":"Changelog","previous_headings":"","what":"jointCalib 0.1.1","title":"jointCalib 0.1.1","text":"initial functionalities causal inference via joint_calib_att joint_calib_cbps bugfixes simplifications additional tests added","code":""},{"path":"https://ncn-foreigners.github.io/jointCalib/news/index.html","id":"jointcalib-010","dir":"Changelog","previous_headings":"","what":"jointCalib 0.1.0","title":"jointCalib 0.1.0","text":"CRAN release: 2023-09-07 CRAN main functionalities joint calibration quantiles totals quantiles","code":""}]
